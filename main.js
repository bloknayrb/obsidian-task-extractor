/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => TaskExtractorPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian4 = require("obsidian");

// src/types.ts
var DEFAULT_FRONTMATTER_FIELDS = [
  { key: "task", defaultValue: "", type: "text", required: true },
  { key: "status", defaultValue: "inbox", type: "select", options: ["inbox", "next", "waiting", "someday", "done", "cancelled"], required: true },
  { key: "priority", defaultValue: "medium", type: "select", options: ["low", "medium", "high", "urgent"], required: true },
  { key: "due", defaultValue: "", type: "date", required: false },
  { key: "project", defaultValue: "", type: "text", required: false },
  { key: "client", defaultValue: "", type: "text", required: false },
  { key: "created", defaultValue: "{{date}}", type: "date", required: true },
  { key: "tags", defaultValue: "task", type: "text", required: false }
];
var DEFAULT_SETTINGS = {
  provider: "openai",
  apiKey: "",
  model: "gpt-4o-mini",
  // Local LLM settings
  ollamaUrl: "http://localhost:11434",
  lmstudioUrl: "http://localhost:1234",
  localModelRefreshInterval: 5,
  // Processing settings
  tasksFolder: "Tasks",
  linkBack: true,
  processedFrontmatterKey: "taskExtractor.processed",
  ownerName: "Bryan Kolb",
  processOnUpdate: false,
  triggerTypes: ["email", "meetingnote", "meeting note", "meeting notes"],
  triggerFrontmatterField: "Type",
  // default to "Type" for backward compatibility
  // Customizable frontmatter
  frontmatterFields: DEFAULT_FRONTMATTER_FIELDS,
  customPrompt: "",
  // Advanced settings
  maxTokens: 800,
  temperature: 0,
  timeout: 30,
  retries: 3,
  // Debug settings
  debugMode: false,
  debugMaxEntries: 1e3
};
function validateSettings(settings, debugLogger) {
  const correlationId = debugLogger ? `validate-settings-${Date.now()}` : void 0;
  const validated = { ...DEFAULT_SETTINGS };
  if (settings.provider && ["openai", "anthropic", "ollama", "lmstudio"].includes(settings.provider)) {
    validated.provider = settings.provider;
  }
  if (typeof settings.apiKey === "string") validated.apiKey = settings.apiKey;
  if (typeof settings.model === "string") validated.model = settings.model;
  if (typeof settings.ollamaUrl === "string") validated.ollamaUrl = settings.ollamaUrl;
  if (typeof settings.lmstudioUrl === "string") validated.lmstudioUrl = settings.lmstudioUrl;
  if (typeof settings.tasksFolder === "string" && settings.tasksFolder.trim()) {
    validated.tasksFolder = settings.tasksFolder.trim();
  }
  if (typeof settings.ownerName === "string" && settings.ownerName.trim()) {
    validated.ownerName = settings.ownerName.trim();
  }
  if (typeof settings.customPrompt === "string") validated.customPrompt = settings.customPrompt;
  if (typeof settings.processedFrontmatterKey === "string") {
    const key = settings.processedFrontmatterKey.trim();
    const parts = key.split(".");
    const yamlKeyPattern = /^[a-zA-Z_][a-zA-Z0-9_-]*$/;
    const isValid = parts.every((part) => part && yamlKeyPattern.test(part));
    if (isValid) {
      validated.processedFrontmatterKey = key;
    }
  }
  if (typeof settings.triggerFrontmatterField === "string") {
    const field = settings.triggerFrontmatterField.trim();
    const yamlKeyPattern = /^[a-zA-Z_][a-zA-Z0-9_.-]*$/;
    if (field && yamlKeyPattern.test(field) && !field.includes("..") && !field.startsWith(".") && !field.endsWith(".")) {
      validated.triggerFrontmatterField = field;
    }
  }
  if (typeof settings.linkBack === "boolean") validated.linkBack = settings.linkBack;
  if (typeof settings.processOnUpdate === "boolean") validated.processOnUpdate = settings.processOnUpdate;
  if (Array.isArray(settings.triggerTypes)) {
    const validTypes = settings.triggerTypes.filter((t) => typeof t === "string" && t.trim().length > 0).map((t) => t.trim());
    if (validTypes.length > 0) {
      validated.triggerTypes = validTypes;
    }
  }
  if (Array.isArray(settings.frontmatterFields)) {
    const validFields = settings.frontmatterFields.filter(
      (f) => f && typeof f.key === "string" && f.key.trim().length > 0 && typeof f.defaultValue === "string" && typeof f.type === "string" && ["text", "date", "select", "boolean"].includes(f.type) && typeof f.required === "boolean"
    );
    if (validFields.length > 0) {
      validated.frontmatterFields = validFields;
    }
  }
  if (typeof settings.localModelRefreshInterval === "number" && !isNaN(settings.localModelRefreshInterval)) {
    validated.localModelRefreshInterval = Math.max(1, Math.min(60, settings.localModelRefreshInterval));
  }
  if (typeof settings.maxTokens === "number" && !isNaN(settings.maxTokens)) {
    validated.maxTokens = Math.max(100, Math.min(2e3, settings.maxTokens));
  }
  if (typeof settings.temperature === "number" && !isNaN(settings.temperature)) {
    validated.temperature = Math.max(0, Math.min(1, settings.temperature));
  }
  if (typeof settings.timeout === "number" && !isNaN(settings.timeout)) {
    validated.timeout = Math.max(10, Math.min(120, settings.timeout));
  }
  if (typeof settings.retries === "number" && !isNaN(settings.retries)) {
    validated.retries = Math.max(1, Math.min(5, settings.retries));
  }
  if (typeof settings.debugMode === "boolean") {
    validated.debugMode = settings.debugMode;
    debugLogger == null ? void 0 : debugLogger.logValidationSuccess("settings", "debugMode", correlationId);
  }
  if (typeof settings.debugMaxEntries === "number" && !isNaN(settings.debugMaxEntries)) {
    const originalValue = settings.debugMaxEntries;
    validated.debugMaxEntries = Math.max(100, Math.min(1e4, settings.debugMaxEntries));
    if (originalValue !== validated.debugMaxEntries) {
      debugLogger == null ? void 0 : debugLogger.logValidation("settings", "debugMaxEntries", originalValue, "100-10000", `Value clamped from ${originalValue} to ${validated.debugMaxEntries}`, correlationId);
    } else {
      debugLogger == null ? void 0 : debugLogger.logValidationSuccess("settings", "debugMaxEntries", correlationId);
    }
  } else if (settings.debugMaxEntries !== void 0) {
    debugLogger == null ? void 0 : debugLogger.logValidation("settings", "debugMaxEntries", settings.debugMaxEntries, "number between 100-10000", "Invalid debug max entries value", correlationId);
  }
  debugLogger == null ? void 0 : debugLogger.log("info", "validation", "Settings validation completed", {
    validatedFieldCount: Object.keys(settings).length,
    correlationId
  }, correlationId);
  return validated;
}

// src/llm-providers.ts
var import_obsidian = require("obsidian");
var LLMProviderManager = class {
  constructor(settings, debugLogger) {
    this.settings = settings;
    this.debugLogger = debugLogger;
    this.serviceCache = /* @__PURE__ */ new Map();
    this.cloudModelCache = /* @__PURE__ */ new Map();
    this.apiKeyMissingNotified = /* @__PURE__ */ new Set();
  }
  // Get service with 30-minute cache TTL
  async getService(provider) {
    const cached = this.serviceCache.get(provider);
    const now = Date.now();
    const cacheValidMs = 30 * 60 * 1e3;
    if (cached && now - cached.lastChecked < cacheValidMs) {
      return cached;
    }
    return await this.detectSingleService(provider);
  }
  // Detect a single service instead of all services
  async detectSingleService(provider) {
    var _a, _b, _c, _d, _e, _f, _g, _h, _i, _j, _k, _l, _m, _n;
    const now = Date.now();
    const correlationId = (_a = this.debugLogger) == null ? void 0 : _a.startOperation("service-detection", `Detecting service: ${provider}`, {
      provider,
      timestamp: now
    });
    if (provider === "ollama") {
      const service = {
        name: "ollama",
        url: this.settings.ollamaUrl,
        available: false,
        models: [],
        lastChecked: now
      };
      (_b = this.debugLogger) == null ? void 0 : _b.log("info", "service-detection", "Checking Ollama availability", {
        provider: "ollama",
        url: this.settings.ollamaUrl,
        endpoint: `${this.settings.ollamaUrl}/api/tags`
      }, correlationId);
      try {
        const startTime = Date.now();
        const rawResponse = await (0, import_obsidian.requestUrl)({
          url: `${this.settings.ollamaUrl}/api/tags`,
          method: "GET"
        });
        const response = this.adaptRequestUrlResponse(rawResponse);
        const connectionTime = Date.now() - startTime;
        if (response.ok) {
          const data = await response.json();
          service.available = true;
          service.models = ((_c = data.models) == null ? void 0 : _c.map((m) => m.name)) || [];
          (_d = this.debugLogger) == null ? void 0 : _d.log("info", "service-detection", "Ollama service detected successfully", {
            provider: "ollama",
            url: this.settings.ollamaUrl,
            available: true,
            modelCount: service.models.length,
            models: service.models,
            connectionTime,
            status: response.status
          }, correlationId);
        } else {
          (_e = this.debugLogger) == null ? void 0 : _e.log("warn", "service-detection", `Ollama service responded with error: ${response.status}`, {
            provider: "ollama",
            url: this.settings.ollamaUrl,
            available: false,
            status: response.status,
            connectionTime
          }, correlationId);
        }
      } catch (error) {
        console.log("Ollama not available:", error.message);
        (_f = this.debugLogger) == null ? void 0 : _f.log("warn", "service-detection", "Ollama service not available", {
          provider: "ollama",
          url: this.settings.ollamaUrl,
          available: false,
          error: error.message,
          errorType: error.name
        }, correlationId);
      }
      this.serviceCache.set("ollama", service);
      (_g = this.debugLogger) == null ? void 0 : _g.log("info", "service-detection", "Ollama service cache updated", {
        provider: "ollama",
        available: service.available,
        modelCount: service.models.length,
        lastChecked: service.lastChecked
      }, correlationId);
      return service;
    }
    if (provider === "lmstudio") {
      const service = {
        name: "lmstudio",
        url: this.settings.lmstudioUrl,
        available: false,
        models: [],
        lastChecked: now
      };
      (_h = this.debugLogger) == null ? void 0 : _h.log("info", "service-detection", "Checking LM Studio availability", {
        provider: "lmstudio",
        url: this.settings.lmstudioUrl,
        endpoint: `${this.settings.lmstudioUrl}/v1/models`
      }, correlationId);
      try {
        const startTime = Date.now();
        const rawResponse = await (0, import_obsidian.requestUrl)({
          url: `${this.settings.lmstudioUrl}/v1/models`,
          method: "GET"
        });
        const response = this.adaptRequestUrlResponse(rawResponse);
        const connectionTime = Date.now() - startTime;
        if (response.ok) {
          const data = await response.json();
          service.available = true;
          service.models = ((_i = data.data) == null ? void 0 : _i.map((m) => m.id)) || [];
          (_j = this.debugLogger) == null ? void 0 : _j.log("info", "service-detection", "LM Studio service detected successfully", {
            provider: "lmstudio",
            url: this.settings.lmstudioUrl,
            available: true,
            modelCount: service.models.length,
            models: service.models,
            connectionTime,
            status: response.status
          }, correlationId);
        } else {
          (_k = this.debugLogger) == null ? void 0 : _k.log("warn", "service-detection", `LM Studio service responded with error: ${response.status}`, {
            provider: "lmstudio",
            url: this.settings.lmstudioUrl,
            available: false,
            status: response.status,
            connectionTime
          }, correlationId);
        }
      } catch (error) {
        console.log("LM Studio not available:", error.message);
        (_l = this.debugLogger) == null ? void 0 : _l.log("warn", "service-detection", "LM Studio service not available", {
          provider: "lmstudio",
          url: this.settings.lmstudioUrl,
          available: false,
          error: error.message,
          errorType: error.name
        }, correlationId);
      }
      this.serviceCache.set("lmstudio", service);
      (_m = this.debugLogger) == null ? void 0 : _m.log("info", "service-detection", "LM Studio service cache updated", {
        provider: "lmstudio",
        available: service.available,
        modelCount: service.models.length,
        lastChecked: service.lastChecked
      }, correlationId);
      return service;
    }
    (_n = this.debugLogger) == null ? void 0 : _n.log("warn", "service-detection", `Unknown provider requested: ${provider}`, {
      provider,
      supportedProviders: ["ollama", "lmstudio"]
    }, correlationId);
    return null;
  }
  // Legacy method for backward compatibility
  async detectServices() {
    await this.getService("ollama");
    await this.getService("lmstudio");
    return this.serviceCache;
  }
  getAvailableServices() {
    return Array.from(this.serviceCache.values()).filter((s) => s.available);
  }
  // Provider-agnostic LLM call with fallback support
  async callLLM(systemPrompt, userPrompt) {
    var _a, _b, _c, _d, _e, _f, _g;
    const provider = this.settings.provider;
    const correlationId = (_a = this.debugLogger) == null ? void 0 : _a.startOperation("llm-call", `Starting LLM call with provider: ${provider}`, {
      provider,
      model: this.settings.model
    });
    if (["openai", "anthropic"].includes(provider) && !this.settings.apiKey) {
      const notificationKey = `${provider}-no-api-key`;
      if (!this.apiKeyMissingNotified.has(notificationKey)) {
        console.warn(`Task Extractor: ${provider.toUpperCase()} API key not configured in plugin settings`);
        this.apiKeyMissingNotified.add(notificationKey);
        (_b = this.debugLogger) == null ? void 0 : _b.log("error", "llm-call", `API key missing for ${provider}`, {
          provider,
          notificationKey
        }, correlationId);
      }
      return null;
    }
    if (this.settings.apiKey) {
      this.apiKeyMissingNotified.delete(`${provider}-no-api-key`);
    }
    for (let attempt = 0; attempt < this.settings.retries; attempt++) {
      const startTime = Date.now();
      (_c = this.debugLogger) == null ? void 0 : _c.log("info", "llm-call", `Attempt ${attempt + 1}/${this.settings.retries} for ${provider}`, {
        provider,
        model: this.settings.model,
        retryAttempt: attempt + 1
      }, correlationId);
      try {
        let result = null;
        switch (provider) {
          case "openai":
            result = await this.callOpenAI(systemPrompt, userPrompt, correlationId);
            break;
          case "anthropic":
            result = await this.callAnthropic(systemPrompt, userPrompt, correlationId);
            break;
          case "ollama":
            result = await this.callOllama(systemPrompt, userPrompt, correlationId);
            break;
          case "lmstudio":
            result = await this.callLMStudio(systemPrompt, userPrompt, correlationId);
            break;
          default:
            throw new Error(`Unsupported provider: ${provider}`);
        }
        if (result) {
          const processingTime = Date.now() - startTime;
          (_d = this.debugLogger) == null ? void 0 : _d.log("info", "llm-call", `LLM call successful on attempt ${attempt + 1}`, {
            provider,
            model: this.settings.model,
            processingTime,
            retryAttempt: attempt + 1,
            responseLength: result.length
          }, correlationId);
          return result;
        }
      } catch (error) {
        const processingTime = Date.now() - startTime;
        console.warn(`Attempt ${attempt + 1} failed for ${provider}:`, error.message);
        (_e = this.debugLogger) == null ? void 0 : _e.log("warn", "llm-call", `Attempt ${attempt + 1} failed for ${provider}`, {
          provider,
          model: this.settings.model,
          error: error.message,
          processingTime,
          retryAttempt: attempt + 1
        }, correlationId);
        if (attempt === this.settings.retries - 1) {
          if (["ollama", "lmstudio"].includes(provider)) {
            (_f = this.debugLogger) == null ? void 0 : _f.log("info", "llm-call", `All attempts failed, trying local fallback`, {
              provider,
              totalAttempts: this.settings.retries
            }, correlationId);
            return await this.tryLocalFallback(systemPrompt, userPrompt, correlationId);
          }
        } else {
          const backoffDelay = 1e3 * (attempt + 1);
          (_g = this.debugLogger) == null ? void 0 : _g.log("info", "llm-call", `Waiting ${backoffDelay}ms before retry`, {
            provider,
            backoffDelay,
            nextAttempt: attempt + 2
          }, correlationId);
          await this.delay(backoffDelay);
        }
      }
    }
    return null;
  }
  async tryLocalFallback(systemPrompt, userPrompt, correlationId) {
    var _a, _b, _c, _d;
    const availableServices = this.getAvailableServices();
    (_a = this.debugLogger) == null ? void 0 : _a.log("info", "llm-call", `Trying local fallback with ${availableServices.length} available services`, {
      availableServices: availableServices.map((s) => s.name),
      primaryProvider: this.settings.provider
    }, correlationId);
    for (const service of availableServices) {
      if (service.name === this.settings.provider) continue;
      try {
        console.log(`Trying fallback to ${service.name}`);
        (_b = this.debugLogger) == null ? void 0 : _b.log("info", "llm-call", `Attempting fallback to ${service.name}`, {
          fallbackProvider: service.name,
          availableModels: service.models
        }, correlationId);
        if (service.name === "ollama") {
          return await this.callOllama(systemPrompt, userPrompt, correlationId);
        } else if (service.name === "lmstudio") {
          return await this.callLMStudio(systemPrompt, userPrompt, correlationId);
        }
      } catch (error) {
        console.warn(`Fallback to ${service.name} failed:`, error.message);
        (_c = this.debugLogger) == null ? void 0 : _c.log("warn", "llm-call", `Fallback to ${service.name} failed`, {
          fallbackProvider: service.name,
          error: error.message
        }, correlationId);
      }
    }
    console.warn("Task Extractor: All LLM services failed. Check your configuration.");
    (_d = this.debugLogger) == null ? void 0 : _d.log("error", "llm-call", "All LLM services failed including fallbacks", {
      primaryProvider: this.settings.provider,
      availableServices: availableServices.map((s) => s.name)
    }, correlationId);
    return null;
  }
  async callOpenAI(systemPrompt, userPrompt, correlationId) {
    var _a, _b, _c, _d, _e, _f, _g, _h, _i;
    const endpoint = "https://api.openai.com/v1/chat/completions";
    const model = this.settings.model || "gpt-4o-mini";
    const body = {
      model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt }
      ],
      temperature: this.settings.temperature,
      max_tokens: this.settings.maxTokens
    };
    const maskedApiKey = this.settings.apiKey ? `...${this.settings.apiKey.slice(-4)}` : "none";
    (_a = this.debugLogger) == null ? void 0 : _a.log("info", "llm-call", "Sending OpenAI API request", {
      provider: "openai",
      model,
      endpoint,
      apiKey: maskedApiKey,
      requestPayload: {
        ...body,
        messages: body.messages.map((m) => ({ role: m.role, contentLength: m.content.length }))
      }
    }, correlationId);
    try {
      const startTime = Date.now();
      const rawResp = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "POST",
        headers: {
          "Authorization": `Bearer ${this.settings.apiKey}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify(body)
      });
      const resp = this.adaptRequestUrlResponse(rawResp);
      const processingTime = Date.now() - startTime;
      if (!resp.ok) {
        const text = await resp.text();
        console.error("OpenAI error", resp.status, text);
        (_b = this.debugLogger) == null ? void 0 : _b.log("error", "llm-call", `OpenAI API error: ${resp.status}`, {
          provider: "openai",
          model,
          status: resp.status,
          statusText: resp.statusText,
          error: text,
          processingTime
        }, correlationId);
        throw new Error(`OpenAI API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      const content = ((_e = (_d = (_c = json == null ? void 0 : json.choices) == null ? void 0 : _c[0]) == null ? void 0 : _d.message) == null ? void 0 : _e.content) || null;
      const tokenUsage = ((_f = json == null ? void 0 : json.usage) == null ? void 0 : _f.total_tokens) || 0;
      (_h = this.debugLogger) == null ? void 0 : _h.log("info", "llm-call", "OpenAI API response received", {
        provider: "openai",
        model,
        status: resp.status,
        tokenUsage,
        responseLength: (content == null ? void 0 : content.length) || 0,
        processingTime,
        responseData: {
          choices: ((_g = json == null ? void 0 : json.choices) == null ? void 0 : _g.length) || 0,
          usage: json == null ? void 0 : json.usage
        }
      }, correlationId);
      return content;
    } catch (e) {
      console.error("callOpenAI error", e);
      (_i = this.debugLogger) == null ? void 0 : _i.log("error", "llm-call", "OpenAI API call failed", {
        provider: "openai",
        model,
        error: e.message
      }, correlationId);
      throw e;
    }
  }
  async callAnthropic(systemPrompt, userPrompt, correlationId) {
    var _a, _b, _c, _d, _e, _f, _g, _h, _i;
    const endpoint = "https://api.anthropic.com/v1/messages";
    const model = this.settings.model || "claude-3-sonnet-20240229";
    const requestBody = {
      model,
      max_tokens: this.settings.maxTokens,
      temperature: this.settings.temperature,
      system: systemPrompt,
      messages: [{
        role: "user",
        content: userPrompt
      }]
    };
    const maskedApiKey = this.settings.apiKey ? `...${this.settings.apiKey.slice(-4)}` : "none";
    (_a = this.debugLogger) == null ? void 0 : _a.log("info", "llm-call", "Sending Anthropic API request", {
      provider: "anthropic",
      model,
      endpoint,
      apiKey: maskedApiKey,
      requestPayload: {
        ...requestBody,
        system: `${systemPrompt.length} chars`,
        messages: requestBody.messages.map((m) => ({ role: m.role, contentLength: m.content.length }))
      }
    }, correlationId);
    try {
      const startTime = Date.now();
      const rawResp = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "POST",
        headers: {
          "x-api-key": this.settings.apiKey,
          "Content-Type": "application/json",
          "anthropic-version": "2023-06-01"
        },
        body: JSON.stringify(requestBody)
      });
      const resp = this.adaptRequestUrlResponse(rawResp);
      const processingTime = Date.now() - startTime;
      if (!resp.ok) {
        const text = await resp.text();
        console.error("Anthropic error", resp.status, text);
        (_b = this.debugLogger) == null ? void 0 : _b.log("error", "llm-call", `Anthropic API error: ${resp.status}`, {
          provider: "anthropic",
          model,
          status: resp.status,
          statusText: resp.statusText,
          error: text,
          processingTime
        }, correlationId);
        throw new Error(`Anthropic API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      const content = ((_d = (_c = json == null ? void 0 : json.content) == null ? void 0 : _c[0]) == null ? void 0 : _d.text) || null;
      const tokenUsage = ((_e = json == null ? void 0 : json.usage) == null ? void 0 : _e.input_tokens) + ((_f = json == null ? void 0 : json.usage) == null ? void 0 : _f.output_tokens) || 0;
      (_h = this.debugLogger) == null ? void 0 : _h.log("info", "llm-call", "Anthropic API response received", {
        provider: "anthropic",
        model,
        status: resp.status,
        tokenUsage,
        responseLength: (content == null ? void 0 : content.length) || 0,
        processingTime,
        responseData: {
          contentBlocks: ((_g = json == null ? void 0 : json.content) == null ? void 0 : _g.length) || 0,
          usage: json == null ? void 0 : json.usage
        }
      }, correlationId);
      return content;
    } catch (e) {
      console.error("callAnthropic error", e);
      (_i = this.debugLogger) == null ? void 0 : _i.log("error", "llm-call", "Anthropic API call failed", {
        provider: "anthropic",
        model,
        error: e.message
      }, correlationId);
      throw e;
    }
  }
  async callOllama(systemPrompt, userPrompt, correlationId) {
    var _a, _b, _c, _d, _e, _f, _g, _h;
    const service = await this.getService("ollama");
    if (!(service == null ? void 0 : service.available) || !service.models.length) {
      (_b = this.debugLogger) == null ? void 0 : _b.log("error", "llm-call", "Ollama service not available or no models loaded", {
        provider: "ollama",
        serviceAvailable: (service == null ? void 0 : service.available) || false,
        modelCount: ((_a = service == null ? void 0 : service.models) == null ? void 0 : _a.length) || 0,
        url: this.settings.ollamaUrl
      }, correlationId);
      throw new Error("Ollama service not available or no models loaded");
    }
    const model = service.models.includes(this.settings.model) ? this.settings.model : service.models[0];
    const endpoint = `${this.settings.ollamaUrl}/api/chat`;
    const requestBody = {
      model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt }
      ],
      stream: false,
      options: {
        temperature: this.settings.temperature,
        num_predict: this.settings.maxTokens
      }
    };
    (_c = this.debugLogger) == null ? void 0 : _c.log("info", "llm-call", "Sending Ollama API request", {
      provider: "ollama",
      model,
      endpoint,
      url: this.settings.ollamaUrl,
      availableModels: service.models,
      requestPayload: {
        ...requestBody,
        messages: requestBody.messages.map((m) => ({ role: m.role, contentLength: m.content.length }))
      }
    }, correlationId);
    try {
      const startTime = Date.now();
      const rawResp = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify(requestBody)
      });
      const resp = this.adaptRequestUrlResponse(rawResp);
      const processingTime = Date.now() - startTime;
      if (!resp.ok) {
        const text = await resp.text();
        console.error("Ollama error", resp.status, text);
        (_d = this.debugLogger) == null ? void 0 : _d.log("error", "llm-call", `Ollama API error: ${resp.status}`, {
          provider: "ollama",
          model,
          status: resp.status,
          statusText: resp.statusText,
          error: text,
          processingTime,
          url: this.settings.ollamaUrl
        }, correlationId);
        throw new Error(`Ollama API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      const content = ((_e = json == null ? void 0 : json.message) == null ? void 0 : _e.content) || null;
      (_g = this.debugLogger) == null ? void 0 : _g.log("info", "llm-call", "Ollama API response received", {
        provider: "ollama",
        model,
        status: resp.status,
        responseLength: (content == null ? void 0 : content.length) || 0,
        processingTime,
        responseData: {
          hasMessage: !!(json == null ? void 0 : json.message),
          messageRole: (_f = json == null ? void 0 : json.message) == null ? void 0 : _f.role
        }
      }, correlationId);
      return content;
    } catch (e) {
      console.error("callOllama error", e);
      (_h = this.debugLogger) == null ? void 0 : _h.log("error", "llm-call", "Ollama API call failed", {
        provider: "ollama",
        model,
        error: e.message,
        url: this.settings.ollamaUrl
      }, correlationId);
      throw e;
    }
  }
  async callLMStudio(systemPrompt, userPrompt, correlationId) {
    var _a, _b, _c, _d, _e, _f, _g, _h, _i, _j, _k;
    const service = await this.getService("lmstudio");
    if (!(service == null ? void 0 : service.available) || !service.models.length) {
      (_b = this.debugLogger) == null ? void 0 : _b.log("error", "llm-call", "LM Studio service not available or no models loaded", {
        provider: "lmstudio",
        serviceAvailable: (service == null ? void 0 : service.available) || false,
        modelCount: ((_a = service == null ? void 0 : service.models) == null ? void 0 : _a.length) || 0,
        url: this.settings.lmstudioUrl
      }, correlationId);
      throw new Error("LM Studio service not available or no models loaded");
    }
    const model = service.models.includes(this.settings.model) ? this.settings.model : service.models[0];
    const endpoint = `${this.settings.lmstudioUrl}/v1/chat/completions`;
    const requestBody = {
      model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt }
      ],
      temperature: this.settings.temperature,
      max_tokens: this.settings.maxTokens
    };
    (_c = this.debugLogger) == null ? void 0 : _c.log("info", "llm-call", "Sending LM Studio API request", {
      provider: "lmstudio",
      model,
      endpoint,
      url: this.settings.lmstudioUrl,
      availableModels: service.models,
      requestPayload: {
        ...requestBody,
        messages: requestBody.messages.map((m) => ({ role: m.role, contentLength: m.content.length }))
      }
    }, correlationId);
    try {
      const startTime = Date.now();
      const rawResp = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "POST",
        headers: {
          "Authorization": "Bearer lm-studio",
          // Placeholder auth
          "Content-Type": "application/json"
        },
        body: JSON.stringify(requestBody)
      });
      const resp = this.adaptRequestUrlResponse(rawResp);
      const processingTime = Date.now() - startTime;
      if (!resp.ok) {
        const text = await resp.text();
        console.error("LM Studio error", resp.status, text);
        (_d = this.debugLogger) == null ? void 0 : _d.log("error", "llm-call", `LM Studio API error: ${resp.status}`, {
          provider: "lmstudio",
          model,
          status: resp.status,
          statusText: resp.statusText,
          error: text,
          processingTime,
          url: this.settings.lmstudioUrl
        }, correlationId);
        throw new Error(`LM Studio API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      const content = ((_g = (_f = (_e = json == null ? void 0 : json.choices) == null ? void 0 : _e[0]) == null ? void 0 : _f.message) == null ? void 0 : _g.content) || null;
      const tokenUsage = ((_h = json == null ? void 0 : json.usage) == null ? void 0 : _h.total_tokens) || 0;
      (_j = this.debugLogger) == null ? void 0 : _j.log("info", "llm-call", "LM Studio API response received", {
        provider: "lmstudio",
        model,
        status: resp.status,
        tokenUsage,
        responseLength: (content == null ? void 0 : content.length) || 0,
        processingTime,
        responseData: {
          choices: ((_i = json == null ? void 0 : json.choices) == null ? void 0 : _i.length) || 0,
          usage: json == null ? void 0 : json.usage
        }
      }, correlationId);
      return content;
    } catch (e) {
      console.error("callLMStudio error", e);
      (_k = this.debugLogger) == null ? void 0 : _k.log("error", "llm-call", "LM Studio API call failed", {
        provider: "lmstudio",
        model,
        error: e.message,
        url: this.settings.lmstudioUrl
      }, correlationId);
      throw e;
    }
  }
  // Fetch available models for cloud providers
  async fetchCloudModels(provider) {
    var _a, _b, _c, _d, _e;
    const correlationId = (_a = this.debugLogger) == null ? void 0 : _a.startOperation("service-detection", `Fetching cloud models for provider: ${provider}`, {
      provider,
      hasApiKey: !!this.settings.apiKey
    });
    if (!this.settings.apiKey) {
      (_b = this.debugLogger) == null ? void 0 : _b.log("warn", "service-detection", `No API key available for ${provider}`, {
        provider
      }, correlationId);
      return [];
    }
    const cacheKey = `${provider}-${this.settings.apiKey.slice(-4)}`;
    if (this.cloudModelCache.has(cacheKey)) {
      const cachedModels = this.cloudModelCache.get(cacheKey) || [];
      (_c = this.debugLogger) == null ? void 0 : _c.log("info", "service-detection", `Using cached models for ${provider}`, {
        provider,
        cacheKey: cacheKey.replace(/-.*$/, "-****"),
        // Mask API key in logs
        modelCount: cachedModels.length,
        models: cachedModels
      }, correlationId);
      return cachedModels;
    }
    (_d = this.debugLogger) == null ? void 0 : _d.log("info", "service-detection", `Cache miss, fetching fresh models for ${provider}`, {
      provider,
      cacheKey: cacheKey.replace(/-.*$/, "-****")
    }, correlationId);
    try {
      if (provider === "openai") {
        return await this.fetchOpenAIModels(correlationId);
      } else if (provider === "anthropic") {
        return await this.fetchAnthropicModels(correlationId);
      }
    } catch (error) {
      console.warn(`Failed to fetch ${provider} models:`, error.message);
      const defaultModels = this.getDefaultModels(provider);
      (_e = this.debugLogger) == null ? void 0 : _e.log("error", "service-detection", `Failed to fetch ${provider} models, using defaults`, {
        provider,
        error: error.message,
        errorType: error.name,
        defaultModels,
        defaultModelCount: defaultModels.length
      }, correlationId);
      return defaultModels;
    }
    return [];
  }
  async fetchOpenAIModels(correlationId) {
    var _a, _b, _c, _d, _e, _f, _g;
    const endpoint = "https://api.openai.com/v1/models";
    const maskedApiKey = this.settings.apiKey ? `...${this.settings.apiKey.slice(-4)}` : "none";
    (_a = this.debugLogger) == null ? void 0 : _a.log("info", "service-detection", "Fetching OpenAI models", {
      provider: "openai",
      endpoint,
      apiKey: maskedApiKey
    }, correlationId);
    try {
      const startTime = Date.now();
      const rawResponse = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "GET",
        headers: {
          "Authorization": `Bearer ${this.settings.apiKey}`,
          "Content-Type": "application/json"
        }
      });
      const response = this.adaptRequestUrlResponse(rawResponse);
      const processingTime = Date.now() - startTime;
      if (!response.ok) {
        (_b = this.debugLogger) == null ? void 0 : _b.log("error", "service-detection", `OpenAI models API error: ${response.status}`, {
          provider: "openai",
          endpoint,
          status: response.status,
          statusText: response.statusText,
          processingTime
        }, correlationId);
        throw new Error(`OpenAI API error: ${response.status}`);
      }
      const data = await response.json();
      const allModels = data.data || [];
      const models = ((_d = (_c = allModels == null ? void 0 : allModels.filter((model) => model.id.includes("gpt") && !model.id.includes("instruct"))) == null ? void 0 : _c.map((model) => model.id)) == null ? void 0 : _d.sort()) || [];
      (_e = this.debugLogger) == null ? void 0 : _e.log("info", "service-detection", "OpenAI models fetched successfully", {
        provider: "openai",
        endpoint,
        status: response.status,
        processingTime,
        totalModelsReceived: allModels.length,
        filteredModelCount: models.length,
        models
      }, correlationId);
      const cacheKey = `openai-${this.settings.apiKey.slice(-4)}`;
      this.cloudModelCache.set(cacheKey, models);
      (_f = this.debugLogger) == null ? void 0 : _f.log("info", "service-detection", "OpenAI models cached successfully", {
        provider: "openai",
        cacheKey: cacheKey.replace(/-.*$/, "-****"),
        // Mask API key in logs
        modelCount: models.length
      }, correlationId);
      return models.length > 0 ? models : this.getDefaultModels("openai");
    } catch (e) {
      (_g = this.debugLogger) == null ? void 0 : _g.log("error", "service-detection", "OpenAI models fetch failed", {
        provider: "openai",
        endpoint,
        error: e.message,
        errorType: e.name
      }, correlationId);
      throw e;
    }
  }
  async fetchAnthropicModels(correlationId) {
    var _a, _b, _c;
    (_a = this.debugLogger) == null ? void 0 : _a.log("info", "service-detection", "Fetching Anthropic models (using known model list)", {
      provider: "anthropic",
      reason: "no-public-models-api"
    }, correlationId);
    const knownModels = [
      "claude-3-5-sonnet-20241022",
      "claude-3-5-haiku-20241022",
      "claude-3-opus-20240229",
      "claude-3-sonnet-20240229",
      "claude-3-haiku-20240307"
    ];
    (_b = this.debugLogger) == null ? void 0 : _b.log("info", "service-detection", "Anthropic models retrieved successfully", {
      provider: "anthropic",
      modelCount: knownModels.length,
      models: knownModels,
      source: "hardcoded-known-models"
    }, correlationId);
    const cacheKey = `anthropic-${this.settings.apiKey.slice(-4)}`;
    this.cloudModelCache.set(cacheKey, knownModels);
    (_c = this.debugLogger) == null ? void 0 : _c.log("info", "service-detection", "Anthropic models cached successfully", {
      provider: "anthropic",
      cacheKey: cacheKey.replace(/-.*$/, "-****"),
      // Mask API key in logs
      modelCount: knownModels.length
    }, correlationId);
    return knownModels;
  }
  getDefaultModels(provider) {
    const defaults = {
      openai: ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
      anthropic: ["claude-3-5-sonnet-20241022", "claude-3-haiku-20240307"],
      ollama: ["llama3.2", "mistral", "codellama"],
      lmstudio: ["local-model"]
    };
    return defaults[provider] || [];
  }
  // Utility methods
  delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
  createTimeoutSignal(ms) {
    const controller = new AbortController();
    setTimeout(() => controller.abort(), ms);
    return controller.signal;
  }
  // Cleanup method
  cleanup() {
    this.cloudModelCache.clear();
    this.apiKeyMissingNotified.clear();
    this.serviceCache.clear();
  }
  // Helper to adapt requestUrl response to fetch-like interface
  adaptRequestUrlResponse(response) {
    return {
      ok: response.status >= 200 && response.status < 300,
      status: response.status,
      statusText: response.status.toString(),
      json: async () => response.json,
      text: async () => response.text
    };
  }
  // Methods for backward compatibility
  getServiceCache() {
    return this.serviceCache;
  }
  getCloudModelCache() {
    return this.cloudModelCache;
  }
  getApiKeyMissingNotified() {
    return this.apiKeyMissingNotified;
  }
};

// src/task-processor.ts
var import_obsidian2 = require("obsidian");
var TaskProcessor = class {
  constructor(app, settings, llmProvider, debugLogger) {
    this.app = app;
    this.settings = settings;
    this.llmProvider = llmProvider;
    this.debugLogger = debugLogger;
    this.processingFiles = /* @__PURE__ */ new Set();
    this.fileChangeDebouncer = /* @__PURE__ */ new Map();
    this.processingQueue = /* @__PURE__ */ new Map();
  }
  /**
   * Conditional logging helper to ensure zero overhead when debug mode is disabled
   */
  log(level, category, message, data, correlationId) {
    var _a;
    if ((_a = this.debugLogger) == null ? void 0 : _a.isEnabled()) {
      this.debugLogger.log(level, category, message, data, correlationId);
    }
  }
  /**
   * Start a new operation for correlation tracking
   */
  startOperation(category, message, data) {
    var _a;
    if ((_a = this.debugLogger) == null ? void 0 : _a.isEnabled()) {
      return this.debugLogger.startOperation(category, message, data);
    }
    return void 0;
  }
  // Debounce file changes to prevent rapid processing
  debounceFileChange(file, callback) {
    const existing = this.fileChangeDebouncer.get(file.path);
    if (existing) {
      clearTimeout(existing);
    }
    this.fileChangeDebouncer.set(file.path, setTimeout(() => {
      callback(file);
      this.fileChangeDebouncer.delete(file.path);
    }, 2e3));
  }
  // When a file is created or modified
  async onFileChanged(file) {
    var _a, _b, _c, _d, _e, _f, _g;
    if (file.extension !== "md") {
      this.log("info", "file-processing", "File skipped: not a markdown file", {
        filePath: file.path,
        extension: file.extension
      });
      return;
    }
    const correlationId = this.startOperation("file-processing", "Processing file", {
      filePath: file.path
    });
    const queueStatus = this.processingQueue.get(file.path);
    if ((queueStatus == null ? void 0 : queueStatus.status) === "processing" || this.processingFiles.has(file.path)) {
      this.log("info", "file-processing", "File skipped: already being processed", {
        filePath: file.path,
        queueStatus: queueStatus == null ? void 0 : queueStatus.status,
        inProcessingSet: this.processingFiles.has(file.path)
      }, correlationId);
      return;
    }
    const processingStatus = {
      status: "queued",
      startTime: Date.now()
    };
    processingStatus.timeout = setTimeout(() => {
      console.warn(`TaskExtractor: File processing timeout for ${file.path}`);
      this.cleanupFileProcessing(file.path);
    }, 3e4);
    this.processingQueue.set(file.path, processingStatus);
    this.processingFiles.add(file.path);
    processingStatus.status = "processing";
    try {
      const cache = this.app.metadataCache.getFileCache(file);
      const front = cache == null ? void 0 : cache.frontmatter;
      if (!front) {
        this.log("info", "file-processing", "File skipped: no frontmatter found", {
          filePath: file.path
        }, correlationId);
        return;
      }
      this.log("info", "file-processing", "File has frontmatter, validating", {
        filePath: file.path,
        frontmatterKeys: Object.keys(front)
      }, correlationId);
      if (!this.settings.triggerTypes || !Array.isArray(this.settings.triggerTypes) || this.settings.triggerTypes.length === 0) {
        console.warn("TaskExtractor: Invalid trigger types configuration, skipping processing");
        this.log("error", "validation", "Invalid trigger types configuration", {
          filePath: file.path,
          triggerTypes: this.settings.triggerTypes
        }, correlationId);
        this.processingFiles.delete(file.path);
        return;
      }
      const processedKey = this.settings.processedFrontmatterKey || "taskExtractor.processed";
      const processedValue = this.getFrontmatterValue(front, processedKey);
      if (processedValue === true || processedValue === "true") {
        this.log("info", "file-processing", "File skipped: already processed", {
          filePath: file.path,
          processedKey,
          processedValue
        }, correlationId);
        return;
      }
      const frontmatterField = this.validateFrontmatterField(this.settings.triggerFrontmatterField, correlationId);
      const typeRaw = this.getFrontmatterValue(front, frontmatterField) || "";
      if (typeRaw) {
        (_a = this.debugLogger) == null ? void 0 : _a.logValidationSuccess("frontmatter", `${frontmatterField}`, correlationId);
      } else {
        (_b = this.debugLogger) == null ? void 0 : _b.logValidation(
          "frontmatter",
          frontmatterField,
          typeRaw,
          "non-empty value",
          "Frontmatter field is empty or missing",
          correlationId
        );
      }
      const type = ("" + typeRaw).toLowerCase();
      const accepted = this.settings.triggerTypes.map((t) => t.toLowerCase());
      this.log("info", "file-processing", "Checking trigger type match", {
        filePath: file.path,
        frontmatterField,
        typeFound: type,
        acceptedTypes: accepted,
        matches: accepted.includes(type)
      }, correlationId);
      if (!accepted.includes(type)) {
        this.log("info", "file-processing", "File skipped: trigger type not matched", {
          filePath: file.path,
          typeFound: type,
          acceptedTypes: accepted
        }, correlationId);
        (_c = this.debugLogger) == null ? void 0 : _c.logValidation(
          "frontmatter",
          `${frontmatterField}.triggerMatch`,
          type,
          `one of: ${accepted.join(", ")}`,
          `Value '${type}' does not match any trigger types`,
          correlationId
        );
        return;
      } else {
        (_d = this.debugLogger) == null ? void 0 : _d.logValidationSuccess("frontmatter", `${frontmatterField}.triggerMatch`, correlationId);
      }
      if (!this.settings.ownerName || this.settings.ownerName.trim().length === 0) {
        console.warn("TaskExtractor: Owner name not configured, skipping processing");
        this.log("error", "validation", "Owner name not configured", {
          filePath: file.path,
          ownerName: this.settings.ownerName
        }, correlationId);
        this.processingFiles.delete(file.path);
        return;
      }
      const content = await this.app.vault.read(file);
      this.log("info", "file-processing", "File content read, proceeding to task extraction", {
        filePath: file.path,
        contentLength: content.length
      }, correlationId);
      const extraction = await this.extractTaskFromContent(content, file.path, correlationId);
      if (extraction && extraction.found) {
        this.log("info", "file-processing", "Tasks found, proceeding to task creation", {
          filePath: file.path,
          tasksFound: "tasks" in extraction ? (_e = extraction.tasks) == null ? void 0 : _e.length : 1
        }, correlationId);
        await this.handleTaskExtraction(extraction, file, correlationId);
      } else {
        this.log("info", "file-processing", "No tasks found in file", {
          filePath: file.path
        }, correlationId);
      }
      await this.markFileProcessed(file, correlationId);
      if (this.processingQueue.has(file.path)) {
        this.processingQueue.get(file.path).status = "completed";
      }
      this.log("info", "file-processing", "File processing completed successfully", {
        filePath: file.path,
        processingTime: Date.now() - (((_f = this.processingQueue.get(file.path)) == null ? void 0 : _f.startTime) || Date.now())
      }, correlationId);
    } catch (err) {
      console.error("TaskExtractor error", err);
      new import_obsidian2.Notice("Task Extractor: error processing file \u2014 see console");
      this.log("error", "error", "File processing failed with error", {
        filePath: file.path,
        error: err instanceof Error ? err.message : String(err),
        stack: err instanceof Error ? err.stack : void 0,
        processingTime: Date.now() - (((_g = this.processingQueue.get(file.path)) == null ? void 0 : _g.startTime) || Date.now())
      }, correlationId);
      if (this.processingQueue.has(file.path)) {
        this.processingQueue.get(file.path).status = "failed";
      }
    } finally {
      this.cleanupFileProcessing(file.path);
    }
  }
  // Centralized cleanup method for atomic processing
  cleanupFileProcessing(filePath) {
    const status = this.processingQueue.get(filePath);
    if (status == null ? void 0 : status.timeout) {
      clearTimeout(status.timeout);
    }
    this.processingQueue.delete(filePath);
    this.processingFiles.delete(filePath);
  }
  // scan vault once on load for unprocessed matching notes
  async scanExistingFiles() {
    const files = this.getUnprocessedFiles();
    const batches = this.chunkArray(files, 5);
    for (const batch of batches) {
      await Promise.all(batch.map((f) => this.onFileChanged(f)));
      await this.delay(100);
    }
  }
  // Get list of unprocessed files that match trigger criteria
  getUnprocessedFiles() {
    const files = this.app.vault.getMarkdownFiles();
    const unprocessedFiles = [];
    for (const f of files) {
      const cache = this.app.metadataCache.getFileCache(f);
      const front = cache == null ? void 0 : cache.frontmatter;
      if (!front) continue;
      const frontmatterField = this.validateFrontmatterField(this.settings.triggerFrontmatterField);
      const typeRaw = this.getFrontmatterValue(front, frontmatterField) || "";
      const type = ("" + typeRaw).toLowerCase();
      const accepted = this.settings.triggerTypes.map((t) => t.toLowerCase());
      const processedValue = this.getFrontmatterValue(front, this.settings.processedFrontmatterKey);
      if (accepted.includes(type) && !(processedValue === true || processedValue === "true")) {
        unprocessedFiles.push(f);
      }
    }
    return unprocessedFiles;
  }
  // Utility function to chunk array into smaller batches
  chunkArray(array, size) {
    const chunks = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
  // Utility function for delays
  delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
  getFrontmatterValue(front, key) {
    if (!front) return void 0;
    if (key.includes(".")) {
      const parts = key.split(".");
      let cur = front;
      for (const p of parts) {
        if (!cur) return void 0;
        cur = cur[p];
      }
      return cur;
    }
    return front[key];
  }
  async markFileProcessed(file, correlationId) {
    if (!this.settings.processedFrontmatterKey) {
      this.log("info", "file-processing", "Skipping processed marker: no processed frontmatter key configured", {
        filePath: file.path
      }, correlationId);
      return;
    }
    try {
      await this.app.fileManager.processFrontMatter(file, (frontmatter) => {
        const keys = this.settings.processedFrontmatterKey.split(".");
        let current = frontmatter;
        for (let i = 0; i < keys.length - 1; i++) {
          const key = keys[i];
          if (!current[key] || typeof current[key] !== "object") {
            current[key] = {};
          }
          current = current[key];
        }
        current[keys[keys.length - 1]] = true;
      });
      this.log("info", "file-processing", "File marked as processed successfully", {
        filePath: file.path,
        processedKey: this.settings.processedFrontmatterKey
      }, correlationId);
    } catch (e) {
      console.warn("Failed to mark file processed with official API:", e);
      this.log("warn", "file-processing", "Failed to mark file processed with official API, trying fallback", {
        filePath: file.path,
        error: e instanceof Error ? e.message : String(e)
      }, correlationId);
      await this.markFileProcessedFallback(file, correlationId);
    }
  }
  // Fallback method using the previous implementation
  async markFileProcessedFallback(file, correlationId) {
    try {
      const content = await this.app.vault.read(file);
      const fmMatch = content.match(/^---\n([\s\S]*?)\n---/);
      let newContent = content;
      if (fmMatch) {
        const fm = fmMatch[1];
        const processedKey = this.settings.processedFrontmatterKey;
        if (!new RegExp("^" + processedKey.replace(".", "\\.") + ":", "m").test(fm)) {
          const lines = fm.split("\n");
          lines.push(`${processedKey}: true`);
          const updatedFm = lines.join("\n");
          newContent = content.replace(fmMatch[0], `---
${updatedFm}
---`);
          await this.app.vault.modify(file, newContent);
        }
      } else {
        const processedKey = this.settings.processedFrontmatterKey;
        newContent = `---
${processedKey}: true
---

` + content;
        await this.app.vault.modify(file, newContent);
      }
      this.log("info", "file-processing", "File marked as processed using fallback method", {
        filePath: file.path,
        processedKey: this.settings.processedFrontmatterKey
      }, correlationId);
    } catch (e) {
      console.warn("Failed to mark file processed with fallback method:", e);
      this.log("error", "file-processing", "Failed to mark file processed with fallback method", {
        filePath: file.path,
        error: e instanceof Error ? e.message : String(e)
      }, correlationId);
    }
  }
  // Shared method for constructing prompts
  buildExtractionPrompt(sourcePath, content) {
    const basePrompt = this.settings.customPrompt || `You are a task extraction specialist. Extract actionable tasks from emails and meeting notes following these strict rules:

EXTRACTION RULES:
- Extract ONLY concrete, actionable tasks explicitly stated or clearly implied
- Use null for uncertain/missing information - DO NOT GUESS
- Extract tasks only for the specified person: ${this.settings.ownerName} (exact name)
- If no clear tasks exist, return {"found": false, "tasks": []}

PRIORITY GUIDELINES:
- high: explicit urgency/deadline mentioned
- medium: standard requests without time pressure  
- low: optional/background items

VALIDATION CONSTRAINTS:
- task_title: 6-100 characters, actionable phrasing
- task_details: max 300 characters, concrete description
- due_date: YYYY-MM-DD format only if explicitly mentioned
- source_excerpt: exact quote (max 150 chars) justifying extraction

Return valid JSON only. Be conservative - accuracy over completeness.`;
    const fieldDescriptions = this.settings.frontmatterFields.filter((f) => f.required || f.key === "task_title" || f.key === "task_details").map((f) => {
      var _a;
      if (f.key === "task" || f.key === "task_title") return "- task_title: short (6-100 words) actionable title";
      if (f.key === "task_details") return "- task_details: 1-3 sentences describing what to do and any context";
      if (f.key === "due") return "- due_date: ISO date YYYY-MM-DD if explicitly present in the text, otherwise null";
      if (f.key === "priority") return `- priority: ${((_a = f.options) == null ? void 0 : _a.join("|")) || "high|medium|low"} (choose best match)`;
      if (f.key === "project") return "- project: project name if mentioned, otherwise null";
      if (f.key === "client") return "- client: client name if mentioned, otherwise null";
      return `- ${f.key}: ${f.defaultValue || "appropriate value based on context"}`;
    });
    const system = `${basePrompt}

When tasks are found, return JSON in this format:
{
  "found": true,
  "tasks": [
    {
      ${fieldDescriptions.join(",\n      ")},
      "source_excerpt": "exact quote from source (max 150 chars)",
      "confidence": "high|medium|low"
    }
  ],
  "confidence": "high|medium|low"
}

When no tasks found, return: {"found": false, "tasks": []}`;
    const user = `SOURCE_PATH: ${sourcePath}
---BEGIN NOTE---
${content}
---END NOTE---`;
    return { system, user };
  }
  // New method for multi-task extraction
  async extractMultipleTasksFromContent(content, sourcePath, correlationId) {
    var _a;
    const { system, user } = this.buildExtractionPrompt(sourcePath, content);
    this.log("info", "llm-call", "LLM prompt constructed for multi-task extraction", {
      filePath: sourcePath,
      systemPromptLength: system.length,
      userPromptLength: user.length,
      contentLength: content.length
    }, correlationId);
    try {
      const raw = await this.llmProvider.callLLM(system, user);
      this.log("info", "llm-call", "LLM response received for multi-task extraction", {
        filePath: sourcePath,
        responseLength: (raw == null ? void 0 : raw.length) || 0,
        responsePreview: (raw == null ? void 0 : raw.substring(0, 200)) || "null"
      }, correlationId);
      const parsed = this.safeParseJSON(raw);
      if (!parsed) {
        this.log("warn", "llm-call", "Failed to parse LLM response as JSON for multi-task extraction", {
          filePath: sourcePath,
          rawResponse: raw
        }, correlationId);
        return { found: false, tasks: [] };
      }
      this.log("info", "llm-call", "LLM response parsed successfully for multi-task extraction", {
        filePath: sourcePath,
        parsedStructure: Object.keys(parsed),
        found: parsed.found || false,
        tasksCount: ((_a = parsed.tasks) == null ? void 0 : _a.length) || 0
      }, correlationId);
      if ("tasks" in parsed && Array.isArray(parsed.tasks)) {
        return parsed;
      }
      if ("found" in parsed && parsed.found) {
        return {
          found: true,
          tasks: [{
            task_title: parsed.task_title || "Unspecified task",
            task_details: parsed.task_details || "",
            due_date: parsed.due_date || null,
            priority: parsed.priority || "medium",
            project: parsed.project || null,
            client: parsed.client || null,
            source_excerpt: parsed.source_excerpt || "",
            confidence: parsed.confidence || "medium"
          }]
        };
      }
      return { found: false, tasks: [] };
    } catch (e) {
      console.error("extractMultipleTasksFromContent error", e);
      this.log("error", "llm-call", "Multi-task extraction failed with error", {
        filePath: sourcePath,
        error: e instanceof Error ? e.message : String(e),
        stack: e instanceof Error ? e.stack : void 0
      }, correlationId);
      return { found: false, tasks: [] };
    }
  }
  // Handle task extraction results (both single and multi-task)
  async handleTaskExtraction(extraction, sourceFile, correlationId) {
    try {
      if ("tasks" in extraction && Array.isArray(extraction.tasks)) {
        this.log("info", "task-creation", "Processing multi-task extraction result", {
          filePath: sourceFile.path,
          tasksCount: extraction.tasks.length
        }, correlationId);
        let createdCount = 0;
        for (const task of extraction.tasks) {
          try {
            await this.createTaskNote(task, sourceFile, correlationId);
            createdCount++;
          } catch (error) {
            console.error(`Failed to create task note for: ${task.task_title}`, error);
            this.log("error", "task-creation", "Failed to create individual task note", {
              filePath: sourceFile.path,
              taskTitle: task.task_title,
              error: error instanceof Error ? error.message : String(error)
            }, correlationId);
          }
        }
        this.log("info", "task-creation", "Multi-task creation completed", {
          filePath: sourceFile.path,
          totalTasks: extraction.tasks.length,
          createdCount,
          failedCount: extraction.tasks.length - createdCount
        }, correlationId);
        if (createdCount > 0) {
          new import_obsidian2.Notice(`Task Extractor: created ${createdCount} task note${createdCount !== 1 ? "s" : ""}`);
        }
      } else {
        this.log("info", "task-creation", "Processing single-task extraction result", {
          filePath: sourceFile.path,
          taskTitle: extraction.task_title
        }, correlationId);
        await this.createTaskNote(extraction, sourceFile, correlationId);
        new import_obsidian2.Notice(`Task Extractor: created task "${extraction.task_title}"`);
      }
    } catch (error) {
      console.error("Error handling task extraction:", error);
      this.log("error", "task-creation", "Task extraction handling failed", {
        filePath: sourceFile.path,
        error: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : void 0
      }, correlationId);
      new import_obsidian2.Notice("Task Extractor: error creating task notes \u2014 see console");
    }
  }
  // Compose prompt, call LLM, and parse response (legacy method for backward compatibility)
  async extractTaskFromContent(content, sourcePath, correlationId) {
    var _a;
    const { system, user } = this.buildExtractionPrompt(sourcePath, content);
    this.log("info", "llm-call", "LLM prompt constructed for task extraction", {
      filePath: sourcePath,
      systemPromptLength: system.length,
      userPromptLength: user.length,
      contentLength: content.length
    }, correlationId);
    try {
      const raw = await this.llmProvider.callLLM(system, user);
      this.log("info", "llm-call", "LLM response received for task extraction", {
        filePath: sourcePath,
        responseLength: (raw == null ? void 0 : raw.length) || 0,
        responsePreview: (raw == null ? void 0 : raw.substring(0, 200)) || "null"
      }, correlationId);
      const parsed = this.safeParseJSON(raw);
      if (!parsed) {
        this.log("warn", "llm-call", "Failed to parse LLM response as JSON", {
          filePath: sourcePath,
          rawResponse: raw
        }, correlationId);
        return { found: false };
      }
      this.log("info", "llm-call", "LLM response parsed successfully", {
        filePath: sourcePath,
        parsedStructure: Object.keys(parsed),
        found: parsed.found || false,
        tasksCount: ((_a = parsed.tasks) == null ? void 0 : _a.length) || (parsed.found ? 1 : 0)
      }, correlationId);
      if (parsed.tasks && Array.isArray(parsed.tasks)) {
        if (parsed.tasks.length > 0) {
          const firstTask = parsed.tasks[0];
          return {
            found: true,
            task_title: firstTask.task_title || "Unspecified task",
            task_details: firstTask.task_details || "",
            due_date: firstTask.due_date || null,
            priority: firstTask.priority || "medium",
            source_excerpt: firstTask.source_excerpt || "",
            ...firstTask
            // Include any additional extracted fields
          };
        } else {
          return { found: false };
        }
      }
      if (!parsed.found) return { found: false };
      return {
        found: true,
        task_title: parsed.task_title || parsed.title || "Unspecified task",
        task_details: parsed.task_details || parsed.details || "",
        due_date: parsed.due_date || null,
        priority: parsed.priority || "medium",
        source_excerpt: parsed.source_excerpt || "",
        ...parsed
        // Include any additional extracted fields
      };
    } catch (e) {
      console.error("extractTaskFromContent error", e);
      this.log("error", "llm-call", "Task extraction failed with error", {
        filePath: sourcePath,
        error: e instanceof Error ? e.message : String(e),
        stack: e instanceof Error ? e.stack : void 0
      }, correlationId);
      return { found: false };
    }
  }
  safeParseJSON(text) {
    if (!text) return null;
    let parsed = null;
    try {
      parsed = JSON.parse(text);
    } catch (e) {
      const m = text.match(/\{[\s\S]*\}/);
      if (m) {
        try {
          parsed = JSON.parse(m[0]);
        } catch (e2) {
          const fixed = m[0].replace(/'/g, '"');
          try {
            parsed = JSON.parse(fixed);
          } catch (e3) {
            return null;
          }
        }
      } else {
        return null;
      }
    }
    if (!parsed || typeof parsed !== "object") return null;
    return this.validateAndNormalizeParsedResult(parsed);
  }
  validateAndNormalizeParsedResult(data) {
    if (typeof data !== "object" || data === null) {
      this.log("warn", "validation", "Parsed data is not an object", {
        dataType: typeof data,
        data
      });
      return null;
    }
    if (data.hasOwnProperty("tasks") && Array.isArray(data.tasks)) {
      const validTasks = [];
      for (const task of data.tasks) {
        if (this.isValidTask(task)) {
          validTasks.push({
            task_title: task.task_title || "Unspecified task",
            task_details: task.task_details || "",
            due_date: task.due_date || null,
            priority: task.priority || "medium",
            project: task.project || null,
            client: task.client || null,
            source_excerpt: task.source_excerpt || "",
            confidence: task.confidence || "medium",
            ...task
          });
        } else {
          this.log("warn", "validation", "Invalid task found in multi-task result", {
            task,
            taskTitle: task == null ? void 0 : task.task_title
          });
        }
      }
      this.log("info", "validation", "Multi-task validation completed", {
        totalTasks: data.tasks.length,
        validTasks: validTasks.length,
        invalidTasks: data.tasks.length - validTasks.length
      });
      return {
        found: data.found === true && validTasks.length > 0,
        tasks: validTasks,
        confidence: data.confidence || "medium"
      };
    }
    if (data.hasOwnProperty("found")) {
      this.log("info", "validation", "Processing legacy single-task format", {
        found: data.found,
        taskTitle: data.task_title || data.title
      });
      return {
        found: data.found === true,
        task_title: data.task_title || data.title || "",
        task_details: data.task_details || data.details || "",
        due_date: data.due_date || null,
        priority: data.priority || "medium",
        source_excerpt: data.source_excerpt || "",
        ...data
      };
    }
    this.log("warn", "validation", "Parsed data does not match expected format", {
      dataKeys: Object.keys(data),
      hasFound: data.hasOwnProperty("found"),
      hasTasks: data.hasOwnProperty("tasks")
    });
    return null;
  }
  isValidTask(task) {
    if (typeof task !== "object" || !task) return false;
    if (!task.task_title || typeof task.task_title !== "string" || task.task_title.trim().length === 0) {
      return false;
    }
    if (task.confidence && !["high", "medium", "low"].includes(task.confidence)) {
      return false;
    }
    if (task.priority && !["high", "medium", "low"].includes(task.priority)) {
      return false;
    }
    if (task.due_date && typeof task.due_date === "string") {
      const dateRegex = /^\d{4}-\d{2}-\d{2}$/;
      if (!dateRegex.test(task.due_date)) {
        return false;
      }
    }
    return true;
  }
  // Create TaskNotescompatible note in tasksFolder
  async createTaskNote(extraction, sourceFile, correlationId) {
    var _a;
    const safeTitle = this.makeFilenameSafe(extraction.task_title || "task");
    let filename = `${safeTitle}.md`;
    let folder = ((_a = this.settings.tasksFolder) == null ? void 0 : _a.trim()) || "Tasks";
    if (!folder || folder.length === 0) {
      folder = "Tasks";
    }
    folder = folder.replace(/[\\/:*?"<>|]/g, "");
    let path = `${folder}/${filename}`;
    let counter = 1;
    while (this.app.vault.getAbstractFileByPath(path)) {
      path = `${folder}/${safeTitle}-${counter}.md`;
      counter++;
    }
    this.log("info", "task-creation", "Creating task note", {
      sourceFile: sourceFile.path,
      taskTitle: extraction.task_title,
      taskPath: path,
      folder,
      filename: path.split("/").pop()
    }, correlationId);
    const lines = [];
    lines.push("---");
    for (const field of this.settings.frontmatterFields) {
      let value = extraction[field.key] || extraction[field.key.replace("_", "")] || field.defaultValue;
      if (value === "{{date}}") {
        value = (/* @__PURE__ */ new Date()).toISOString().split("T")[0];
      }
      if (field.key === "task" && !value && extraction.task_title) {
        value = extraction.task_title;
      }
      if (value) {
        if (field.type === "text" && typeof value === "string" && value.includes(" ")) {
          lines.push(`${field.key}: "${value}"`);
        } else {
          lines.push(`${field.key}: ${value}`);
        }
      }
    }
    lines.push("---");
    lines.push("");
    lines.push(extraction.task_details || "");
    lines.push("");
    if (this.settings.linkBack) {
      const link = `[[${sourceFile.path}]]`;
      lines.push(`Source: ${link}`);
    }
    if (extraction.source_excerpt) {
      lines.push("");
      lines.push("> Justification excerpt:");
      lines.push("> " + extraction.source_excerpt.replace(/\n/g, " "));
    }
    const final = lines.join("\n");
    try {
      await this.app.vault.create(path, final);
      this.log("info", "task-creation", "Task note created successfully", {
        sourceFile: sourceFile.path,
        taskTitle: extraction.task_title,
        taskPath: path,
        contentLength: final.length
      }, correlationId);
      new import_obsidian2.Notice(`Task Extractor: created task "${extraction.task_title}"`);
    } catch (e) {
      console.error("Failed to create task note", e);
      this.log("error", "task-creation", "Failed to create task note", {
        sourceFile: sourceFile.path,
        taskTitle: extraction.task_title,
        taskPath: path,
        error: e instanceof Error ? e.message : String(e),
        stack: e instanceof Error ? e.stack : void 0
      }, correlationId);
      new import_obsidian2.Notice("Task Extractor: failed to create task note \u2014 see console");
    }
  }
  makeFilenameSafe(title) {
    return title.replace(/[\\/:*?"<>|#%{}\\^~\[\]`;'@&=+]/g, "").replace(/\s+/g, "-").slice(0, 120);
  }
  /**
   * Validates frontmatter field name with graceful fallback to "Type"
   * Ensures the field name is valid for YAML and safe to use
   */
  validateFrontmatterField(fieldName, correlationId) {
    var _a, _b, _c, _d;
    if (!fieldName || typeof fieldName !== "string" || fieldName.trim().length === 0) {
      console.warn('TaskExtractor: Empty frontmatter field name, falling back to "Type"');
      (_a = this.debugLogger) == null ? void 0 : _a.logValidation(
        "frontmatter",
        "fieldName",
        fieldName,
        "non-empty string",
        'Empty frontmatter field name, using fallback "Type"',
        correlationId
      );
      return "Type";
    }
    const trimmed = fieldName.trim();
    const yamlKeyPattern = /^[a-zA-Z_][a-zA-Z0-9_.-]*$/;
    if (!yamlKeyPattern.test(trimmed)) {
      console.warn(`TaskExtractor: Invalid frontmatter field name "${trimmed}", falling back to "Type"`);
      (_b = this.debugLogger) == null ? void 0 : _b.logValidation(
        "frontmatter",
        "fieldName",
        trimmed,
        "valid YAML key pattern (^[a-zA-Z_][a-zA-Z0-9_.-]*$)",
        'Invalid YAML key format, using fallback "Type"',
        correlationId
      );
      return "Type";
    }
    if (trimmed.includes("..") || trimmed.startsWith(".") || trimmed.endsWith(".")) {
      console.warn(`TaskExtractor: Problematic frontmatter field name "${trimmed}", falling back to "Type"`);
      (_c = this.debugLogger) == null ? void 0 : _c.logValidation(
        "frontmatter",
        "fieldName",
        trimmed,
        "valid YAML key without problematic dot patterns",
        'Problematic dot pattern in field name, using fallback "Type"',
        correlationId
      );
      return "Type";
    }
    (_d = this.debugLogger) == null ? void 0 : _d.logValidationSuccess("frontmatter", "fieldName", correlationId);
    return trimmed;
  }
  // Enhanced cleanup method with processing queue management
  cleanup() {
    this.fileChangeDebouncer.forEach((timeout) => clearTimeout(timeout));
    this.fileChangeDebouncer.clear();
    this.processingQueue.forEach((status) => {
      if (status.timeout) {
        clearTimeout(status.timeout);
      }
    });
    this.processingQueue.clear();
    this.processingFiles.clear();
  }
  // Methods for backward compatibility
  getProcessingFiles() {
    return this.processingFiles;
  }
};

// src/settings.ts
var import_obsidian3 = require("obsidian");
var ExtractorSettingTab = class extends import_obsidian3.PluginSettingTab {
  constructor(app, plugin, settings, llmProvider) {
    super(app, plugin);
    this.plugin = plugin;
    this.settings = settings;
    this.llmProvider = llmProvider;
    this.saveTimeout = null;
  }
  // Debounced save to reduce save frequency
  debouncedSave() {
    if (this.saveTimeout) {
      clearTimeout(this.saveTimeout);
    }
    this.saveTimeout = setTimeout(async () => {
      await this.plugin.saveSettings();
      this.saveTimeout = null;
    }, 500);
  }
  // Clean up timeout on hide
  hide() {
    if (this.saveTimeout) {
      clearTimeout(this.saveTimeout);
      this.saveTimeout = null;
    }
    super.hide();
  }
  /**
   * Validates frontmatter field name according to YAML key format
   * Returns a valid field name or defaults to "Type"
   */
  validateFrontmatterField(fieldName) {
    if (!fieldName || fieldName.length === 0) {
      return "Type";
    }
    const yamlKeyPattern = /^[a-zA-Z_][a-zA-Z0-9_.-]*$/;
    if (!yamlKeyPattern.test(fieldName)) {
      return "Type";
    }
    if (fieldName.includes("..") || fieldName.startsWith(".") || fieldName.endsWith(".")) {
      return "Type";
    }
    return fieldName;
  }
  /**
   * Shows validation feedback to the user
   */
  showValidationFeedback(inputEl, message) {
    inputEl.style.borderColor = "#ff6b6b";
    inputEl.style.backgroundColor = "rgba(255, 107, 107, 0.1)";
    inputEl.title = message;
    setTimeout(() => {
      inputEl.style.borderColor = "";
      inputEl.style.backgroundColor = "";
      inputEl.title = "";
    }, 3e3);
  }
  /**
   * Validates and clamps numeric values with enhanced error handling
   */
  validateNumericInput(value, min, max, defaultValue) {
    if (isNaN(value)) {
      return {
        value: defaultValue,
        isValid: false,
        message: `Invalid number. Using default value ${defaultValue}.`
      };
    }
    if (value < min) {
      return {
        value: min,
        isValid: false,
        message: `Value too low. Minimum is ${min}.`
      };
    }
    if (value > max) {
      return {
        value: max,
        isValid: false,
        message: `Value too high. Maximum is ${max}.`
      };
    }
    return { value, isValid: true };
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Task Extractor Settings" });
    this.addProviderSection(containerEl);
    this.addLocalLLMSection(containerEl);
    this.addProcessingSection(containerEl);
    this.addFrontmatterSection(containerEl);
    this.addDebugSection(containerEl);
    this.addAdvancedSection(containerEl);
  }
  addProviderSection(containerEl) {
    containerEl.createEl("h3", { text: "LLM Provider Configuration" });
    const statusEl = containerEl.createEl("div", { cls: "task-extractor-status" });
    this.updateServiceStatus(statusEl);
    new import_obsidian3.Setting(containerEl).setName("Provider").setDesc("Choose LLM provider. Local providers (Ollama/LM Studio) require the service to be running.").addDropdown((cb) => cb.addOption("openai", "OpenAI").addOption("anthropic", "Anthropic").addOption("ollama", "Ollama (Local)").addOption("lmstudio", "LM Studio (Local)").setValue(this.settings.provider).onChange((v) => {
      this.settings.provider = v;
      this.debouncedSave();
      this.llmProvider.getApiKeyMissingNotified().clear();
      this.updateServiceStatus(statusEl);
      this.display();
    }));
    if (["openai", "anthropic"].includes(this.settings.provider)) {
      new import_obsidian3.Setting(containerEl).setName("API Key").setDesc("Your API key for the selected provider. Models will be loaded automatically once entered.").addText((text) => text.setPlaceholder("sk-... or claude-...").setValue(this.settings.apiKey).onChange((v) => {
        this.settings.apiKey = v.trim();
        this.debouncedSave();
        const oldCacheKeys = Array.from(this.llmProvider.getCloudModelCache().keys()).filter((key) => key.startsWith(this.settings.provider));
        oldCacheKeys.forEach((key) => this.llmProvider.getCloudModelCache().delete(key));
        this.llmProvider.getApiKeyMissingNotified().clear();
        this.display();
      }));
    }
    this.addModelSetting(containerEl);
  }
  async addModelSetting(containerEl) {
    const modelContainer = containerEl.createDiv();
    const provider = this.settings.provider;
    const service = this.llmProvider.getServiceCache().get(provider);
    if (["ollama", "lmstudio"].includes(provider) && (service == null ? void 0 : service.available) && service.models.length > 0) {
      new import_obsidian3.Setting(modelContainer).setName("Model").setDesc(`Select from ${service.models.length} available ${provider} models.`).addDropdown((cb) => {
        service.models.forEach((model) => cb.addOption(model, model));
        cb.setValue(this.settings.model || service.models[0]).onChange((v) => {
          this.settings.model = v;
          this.debouncedSave();
        });
      });
    } else if (["openai", "anthropic"].includes(provider) && this.settings.apiKey) {
      const loadingSetting = new import_obsidian3.Setting(modelContainer).setName("Model").setDesc("Loading available models...");
      try {
        const availableModels = await this.llmProvider.fetchCloudModels(provider);
        modelContainer.empty();
        new import_obsidian3.Setting(modelContainer).setName("Model").setDesc(`Select from ${availableModels.length} available ${provider} models.`).addDropdown((cb) => {
          availableModels.forEach((model) => cb.addOption(model, model));
          const currentModel = this.settings.model;
          const defaultModel = availableModels.includes(currentModel) ? currentModel : availableModels[0];
          cb.setValue(defaultModel).onChange((v) => {
            this.settings.model = v;
            this.debouncedSave();
          });
        });
        new import_obsidian3.Setting(modelContainer).setName("Refresh Models").setDesc("Reload the list of available models from the API.").addButton((button) => button.setButtonText("Refresh").onClick(async () => {
          this.llmProvider.getCloudModelCache().clear();
          this.display();
        }));
      } catch (error) {
        modelContainer.empty();
        this.addFallbackModelSetting(modelContainer, provider);
      }
    } else {
      this.addFallbackModelSetting(modelContainer, provider);
    }
  }
  addFallbackModelSetting(container, provider) {
    const defaultModels = {
      openai: "gpt-4o-mini",
      anthropic: "claude-3-haiku-20240307",
      ollama: "llama3.2",
      lmstudio: "local-model"
    };
    const description = ["ollama", "lmstudio"].includes(provider) ? `Enter model name. Service not detected or no models available.` : `Enter model name manually.`;
    new import_obsidian3.Setting(container).setName("Model").setDesc(description).addText((text) => text.setPlaceholder(defaultModels[provider] || "").setValue(this.settings.model).onChange((v) => {
      this.settings.model = v.trim();
      this.debouncedSave();
    }));
  }
  addLocalLLMSection(containerEl) {
    containerEl.createEl("h3", { text: "Local LLM Configuration" });
    if (this.settings.provider === "ollama") {
      new import_obsidian3.Setting(containerEl).setName("Ollama URL").setDesc("URL for your Ollama instance.").addText((text) => text.setValue(this.settings.ollamaUrl).onChange((v) => {
        this.settings.ollamaUrl = v.trim();
        this.debouncedSave();
      }));
    }
    if (this.settings.provider === "lmstudio") {
      new import_obsidian3.Setting(containerEl).setName("LM Studio URL").setDesc("URL for your LM Studio instance.").addText((text) => text.setValue(this.settings.lmstudioUrl).onChange((v) => {
        this.settings.lmstudioUrl = v.trim();
        this.debouncedSave();
      }));
    }
    this.addSliderWithInput(
      containerEl,
      "Model Refresh Interval",
      "How often to check for available models (minutes).",
      this.settings.localModelRefreshInterval,
      1,
      60,
      1,
      (v) => {
        this.settings.localModelRefreshInterval = v;
        this.debouncedSave();
      }
    );
  }
  addProcessingSection(containerEl) {
    containerEl.createEl("h3", { text: "Processing Settings" });
    new import_obsidian3.Setting(containerEl).setName("Owner name").setDesc("Exact name the LLM should look for when deciding tasks.").addText((text) => text.setPlaceholder("Bryan Kolb").setValue(this.settings.ownerName).onChange((v) => {
      this.settings.ownerName = v.trim();
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Tasks folder").setDesc("Folder where generated task notes will be created.").addText((text) => text.setValue(this.settings.tasksFolder).onChange((v) => {
      this.settings.tasksFolder = v.trim();
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Trigger note types").setDesc("Comma-separated list of note types to process (from frontmatter Type field).").addText((text) => text.setValue(this.settings.triggerTypes.join(", ")).onChange((v) => {
      this.settings.triggerTypes = v.split(",").map((s) => s.trim()).filter((s) => s.length > 0);
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Frontmatter field for filtering").setDesc('The frontmatter field name to use for filtering notes (e.g., "Type", "Category", "NoteType").').addText((text) => text.setPlaceholder("Type").setValue(this.settings.triggerFrontmatterField).onChange((v) => {
      const validatedField = this.validateFrontmatterField(v.trim());
      this.settings.triggerFrontmatterField = validatedField;
      this.debouncedSave();
      if (validatedField !== v.trim()) {
        text.setValue(validatedField);
        this.showValidationFeedback(text.inputEl, 'Invalid field name. Using default "Type".');
      }
    }));
    new import_obsidian3.Setting(containerEl).setName("Process edits as well as new files").setDesc("If enabled, modifications to matching notes will be processed too.").addToggle((toggle) => toggle.setValue(this.settings.processOnUpdate).onChange((v) => {
      this.settings.processOnUpdate = v;
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Link back to source").setDesc("Insert a link back to the source note in generated task notes.").addToggle((toggle) => toggle.setValue(this.settings.linkBack).onChange((v) => {
      this.settings.linkBack = v;
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Processed marker key").setDesc("Frontmatter key to mark processed notes.").addText((text) => text.setValue(this.settings.processedFrontmatterKey).onChange((v) => {
      this.settings.processedFrontmatterKey = v.trim();
      this.debouncedSave();
    }));
  }
  addFrontmatterSection(containerEl) {
    containerEl.createEl("h3", { text: "Task Note Frontmatter" });
    new import_obsidian3.Setting(containerEl).setName("Add Field").setDesc("Add a new frontmatter field").addButton((button) => button.setButtonText("Add Field").onClick(() => {
      this.settings.frontmatterFields.push({
        key: "new_field",
        defaultValue: "",
        type: "text",
        required: false
      });
      this.debouncedSave();
      this.display();
    }));
    this.settings.frontmatterFields.forEach((field, index) => {
      const fieldContainer = containerEl.createDiv({ cls: "task-extractor-field" });
      new import_obsidian3.Setting(fieldContainer).setName(`Field ${index + 1}: ${field.key}`).setDesc(`Type: ${field.type}, Required: ${field.required ? "Yes" : "No"}`).addButton((button) => button.setButtonText("Remove").onClick(() => {
        this.settings.frontmatterFields.splice(index, 1);
        this.debouncedSave();
        this.display();
      }));
    });
    new import_obsidian3.Setting(containerEl).setName("Custom Prompt").setDesc("Override the default task extraction prompt. Leave empty to use default.").addTextArea((text) => text.setPlaceholder("Enter custom prompt...").setValue(this.settings.customPrompt).onChange((v) => {
      this.settings.customPrompt = v;
      this.debouncedSave();
    }));
  }
  addDebugSection(containerEl) {
    containerEl.createEl("h3", { text: "Debug Settings" });
    new import_obsidian3.Setting(containerEl).setName("Debug Mode").setDesc("Enable debug logging to monitor plugin activities. Logs are stored in memory only and cleared when Obsidian restarts.").addToggle((toggle) => toggle.setValue(this.settings.debugMode).onChange((v) => {
      this.settings.debugMode = v;
      this.debouncedSave();
      this.display();
    }));
    if (this.settings.debugMode) {
      this.addSliderWithInput(
        containerEl,
        "Max Debug Entries",
        "Maximum number of debug log entries to keep in memory. Older entries are automatically removed.",
        this.settings.debugMaxEntries,
        100,
        1e4,
        100,
        (v) => {
          this.settings.debugMaxEntries = v;
          this.debouncedSave();
        }
      );
    }
  }
  addAdvancedSection(containerEl) {
    containerEl.createEl("h3", { text: "Advanced Settings" });
    this.addSliderWithInput(
      containerEl,
      "Max Tokens",
      "Maximum tokens to generate.",
      this.settings.maxTokens,
      100,
      2e3,
      50,
      (v) => {
        this.settings.maxTokens = v;
        this.debouncedSave();
      }
    );
    this.addSliderWithInput(
      containerEl,
      "Temperature",
      "Creativity level (0 = deterministic, 1 = creative).",
      this.settings.temperature,
      0,
      1,
      0.1,
      (v) => {
        this.settings.temperature = v;
        this.debouncedSave();
      }
    );
    this.addSliderWithInput(
      containerEl,
      "Timeout (seconds)",
      "Request timeout for LLM calls.",
      this.settings.timeout,
      10,
      120,
      5,
      (v) => {
        this.settings.timeout = v;
        this.debouncedSave();
      }
    );
    this.addSliderWithInput(
      containerEl,
      "Retry Attempts",
      "Number of retry attempts for failed requests.",
      this.settings.retries,
      1,
      5,
      1,
      (v) => {
        this.settings.retries = v;
        this.debouncedSave();
      }
    );
  }
  /**
   * Helper method to create an enhanced slider with input field
   * Provides bidirectional synchronization between slider and number input
   */
  addSliderWithInput(containerEl, name, desc, value, min, max, step, onChange) {
    const setting = new import_obsidian3.Setting(containerEl).setName(name).setDesc(desc);
    const controlContainer = setting.controlEl.createDiv({ cls: "task-extractor-slider-input-container" });
    const sliderEl = controlContainer.createEl("input", {
      type: "range",
      cls: "task-extractor-slider"
    });
    sliderEl.min = min.toString();
    sliderEl.max = max.toString();
    sliderEl.step = step.toString();
    sliderEl.value = value.toString();
    const inputEl = controlContainer.createEl("input", {
      type: "number",
      cls: "task-extractor-number-input"
    });
    inputEl.min = min.toString();
    inputEl.max = max.toString();
    inputEl.step = step.toString();
    inputEl.value = value.toString();
    sliderEl.addEventListener("input", () => {
      const newValue = parseFloat(sliderEl.value);
      const validation = this.validateNumericInput(newValue, min, max, value);
      inputEl.value = validation.value.toString();
      onChange(validation.value);
    });
    inputEl.addEventListener("input", () => {
      const newValue = parseFloat(inputEl.value);
      const validation = this.validateNumericInput(newValue, min, max, value);
      if (!validation.isValid) {
        inputEl.value = validation.value.toString();
        this.showValidationFeedback(inputEl, validation.message || "Invalid value");
      }
      sliderEl.value = validation.value.toString();
      onChange(validation.value);
    });
    inputEl.addEventListener("blur", () => {
      const newValue = parseFloat(inputEl.value);
      const validation = this.validateNumericInput(newValue, min, max, value);
      inputEl.value = validation.value.toString();
      sliderEl.value = validation.value.toString();
      if (!validation.isValid) {
        this.showValidationFeedback(inputEl, validation.message || "Value corrected");
      }
    });
    controlContainer.style.display = "flex";
    controlContainer.style.alignItems = "center";
    controlContainer.style.gap = "12px";
    controlContainer.style.width = "100%";
    sliderEl.style.flex = "1";
    sliderEl.style.minWidth = "120px";
    sliderEl.style.height = "20px";
    inputEl.style.width = "80px";
    inputEl.style.textAlign = "center";
    inputEl.style.padding = "4px 8px";
    inputEl.style.border = "1px solid var(--background-modifier-border)";
    inputEl.style.borderRadius = "4px";
    inputEl.style.backgroundColor = "var(--background-primary)";
    inputEl.style.color = "var(--text-normal)";
    inputEl.style.fontSize = "13px";
  }
  updateServiceStatus(statusEl) {
    statusEl.empty();
    const provider = this.settings.provider;
    const service = this.llmProvider.getServiceCache().get(provider);
    if (["ollama", "lmstudio"].includes(provider)) {
      if (service == null ? void 0 : service.available) {
        statusEl.createEl("div", {
          text: `\u2705 ${provider} connected (${service.models.length} models)`,
          cls: "task-extractor-status-success"
        });
      } else {
        statusEl.createEl("div", {
          text: `\u274C ${provider} not available`,
          cls: "task-extractor-status-error"
        });
      }
    } else {
      if (this.settings.apiKey) {
        statusEl.createEl("div", {
          text: `\u2705 ${provider} API key configured`,
          cls: "task-extractor-status-success"
        });
      } else {
        statusEl.createEl("div", {
          text: `\u274C ${provider} API key required`,
          cls: "task-extractor-status-error"
        });
      }
    }
  }
};

// src/debug-logger.ts
var DebugLogger = class {
  constructor(config) {
    this.logs = [];
    this.correlationCounter = 0;
    this.logFailureCount = 0;
    this.maxLogFailures = 5;
    // Performance optimization fields
    this.entryPool = [];
    this.maxPoolSize = 100;
    this.lastCleanupTime = 0;
    this.cleanupInterval = 3e4;
    // 30 seconds
    this.logCount = 0;
    this.totalLogTime = 0;
    this.config = config;
  }
  /**
   * Log a debug entry with specified level, category, and optional data
   * Optimized with object pooling and memory management
   */
  log(level, category, message, data, correlationId) {
    if (!this.config.enabled) {
      return;
    }
    this.safeLog(() => {
      const startTime = performance.now();
      const entry = this.getPooledEntry();
      entry.timestamp = Date.now();
      entry.level = level;
      entry.category = category;
      entry.message = message;
      entry.correlationId = correlationId;
      entry.data = data ? this.cloneData(data) : void 0;
      entry.errorContext = void 0;
      this.logs.push(entry);
      this.logCount++;
      this.totalLogTime += performance.now() - startTime;
      this.performMemoryManagement();
    });
  }
  /**
   * Start a new operation and return a correlation ID for tracking related log entries
   */
  startOperation(category, message, data) {
    const correlationId = `op-${++this.correlationCounter}-${Date.now()}`;
    this.log("info", category, message, data, correlationId);
    return correlationId;
  }
  /**
   * Get all current log entries
   */
  getLogs() {
    return [...this.logs];
  }
  /**
   * Clear all log entries and return them to pool
   */
  clearLogs() {
    this.returnEntriesToPool(this.logs);
    this.logs = [];
    this.correlationCounter = 0;
  }
  /**
   * Export logs as formatted text string with optimized serialization
   */
  exportLogs() {
    if (this.logs.length === 0) {
      return "No debug logs available.";
    }
    const parts = [];
    parts.push("=== Obsidian Task Extractor Debug Logs ===\n");
    parts.push(`Generated: ${(/* @__PURE__ */ new Date()).toISOString()}
`);
    parts.push(`Total Entries: ${this.logs.length}
`);
    parts.push("");
    const lines = new Array(this.logs.length * 3);
    let lineIndex = 0;
    for (const entry of this.logs) {
      const timestamp = new Date(entry.timestamp).toISOString();
      const correlationPart = entry.correlationId ? ` [${entry.correlationId}]` : "";
      lines[lineIndex++] = `[${timestamp}] ${entry.level.toUpperCase()} ${entry.category}${correlationPart}: ${entry.message}`;
      if (entry.data && Object.keys(entry.data).length > 0) {
        try {
          const serializedData = this.optimizedStringify(entry.data);
          lines[lineIndex++] = `  Data: ${serializedData.split("\n").join("\n  ")}`;
        } catch (error) {
          lines[lineIndex++] = "  Data: [Serialization Error]";
        }
      }
      lines[lineIndex++] = "";
    }
    lines.length = lineIndex;
    parts.push(lines.join("\n"));
    return parts.join("\n");
  }
  /**
   * Remove old entries to maintain memory limits with automatic rotation
   * Keeps the most recent entries up to maxEntries limit
   */
  cleanup() {
    if (this.logs.length > this.config.maxEntries) {
      const entriesToRemove = this.logs.length - this.config.maxEntries;
      const removedEntries = this.logs.splice(0, entriesToRemove);
      this.returnEntriesToPool(removedEntries);
    }
  }
  /**
   * Update the logger configuration with performance optimizations
   */
  updateConfig(config) {
    this.config = { ...this.config, ...config };
    if (!this.config.enabled) {
      this.clearLogs();
      this.entryPool = [];
    }
    if (this.logs.length > this.config.maxEntries) {
      this.cleanup();
    }
  }
  /**
   * Get current configuration
   */
  getConfig() {
    return { ...this.config };
  }
  /**
   * Check if debug logging is currently enabled
   */
  isEnabled() {
    return this.config.enabled;
  }
  /**
   * Log an error with detailed context including stack trace
   * Optimized with object pooling
   */
  logError(message, error, category = "error", additionalData, correlationId) {
    if (!this.config.enabled) {
      return;
    }
    this.safeLog(() => {
      const startTime = performance.now();
      const errorContext = this.extractErrorContext(error, additionalData);
      const entry = this.getPooledEntry();
      entry.timestamp = Date.now();
      entry.level = "error";
      entry.category = category;
      entry.message = message;
      entry.data = additionalData ? this.cloneData(additionalData) : void 0;
      entry.correlationId = correlationId;
      entry.errorContext = errorContext;
      this.logs.push(entry);
      this.logCount++;
      this.totalLogTime += performance.now() - startTime;
      this.performMemoryManagement();
    });
  }
  /**
   * Log validation errors with detailed field and value context
   * Optimized with object pooling
   */
  logValidation(validationType, fieldName, providedValue, expectedFormat, errorReason, correlationId) {
    if (!this.config.enabled) {
      return;
    }
    this.safeLog(() => {
      const startTime = performance.now();
      const validationContext = {
        validationType,
        fieldName,
        providedValue: this.sanitizeValue(providedValue),
        expectedFormat,
        errorReason
      };
      const entry = this.getPooledEntry();
      entry.timestamp = Date.now();
      entry.level = "warn";
      entry.category = "validation";
      entry.message = `Validation failed for ${validationType}.${fieldName}: ${errorReason}`;
      entry.data = validationContext;
      entry.correlationId = correlationId;
      entry.errorContext = void 0;
      this.logs.push(entry);
      this.logCount++;
      this.totalLogTime += performance.now() - startTime;
      this.performMemoryManagement();
    });
  }
  /**
   * Log successful validation for debugging purposes
   */
  logValidationSuccess(validationType, fieldName, correlationId) {
    if (!this.config.enabled) {
      return;
    }
    this.safeLog(() => {
      this.log(
        "info",
        "validation",
        `Validation passed for ${validationType}.${fieldName}`,
        { validationType, fieldName },
        correlationId
      );
    });
  }
  /**
   * Safely execute logging with graceful degradation
   */
  safeLog(logOperation) {
    try {
      logOperation();
      this.logFailureCount = 0;
    } catch (error) {
      this.handleLoggingFailure(error);
    }
  }
  /**
   * Handle logging failures with graceful degradation
   */
  handleLoggingFailure(error) {
    this.logFailureCount++;
    if (this.logFailureCount >= this.maxLogFailures) {
      this.config.enabled = false;
      console.warn("DebugLogger: Disabled after repeated failures. Last error:", error);
      return;
    }
    console.warn("DebugLogger: Logging operation failed:", error);
  }
  /**
   * Extract comprehensive error context from error objects
   */
  extractErrorContext(error, additionalData) {
    const context = {
      additionalData
    };
    if (error instanceof Error) {
      context.errorName = error.name;
      context.errorMessage = error.message;
      context.errorStack = error.stack;
    } else if (error && typeof error === "object") {
      try {
        context.originalError = JSON.stringify(error);
      } catch (e) {
        context.originalError = String(error);
      }
    } else {
      context.originalError = String(error);
    }
    return context;
  }
  /**
   * Sanitize values to prevent logging sensitive information
   */
  sanitizeValue(value) {
    if (typeof value === "string") {
      if (value.length > 10 && /^[a-zA-Z0-9_-]+$/.test(value)) {
        return `${value.substring(0, 4)}...${value.substring(value.length - 4)}`;
      }
    }
    if (value && typeof value === "object") {
      const sanitized = { ...value };
      const sensitiveFields = ["apiKey", "token", "password", "secret", "key"];
      for (const field of sensitiveFields) {
        if (field in sanitized) {
          sanitized[field] = "[REDACTED]";
        }
      }
      return sanitized;
    }
    return value;
  }
  /**
   * Get a pooled entry or create a new one to reduce GC pressure
   */
  getPooledEntry() {
    if (this.entryPool.length > 0) {
      return this.entryPool.pop();
    }
    return {
      timestamp: 0,
      level: "info",
      category: "file-processing",
      message: "",
      correlationId: void 0,
      data: void 0,
      errorContext: void 0
    };
  }
  /**
   * Return entries to the pool for reuse
   */
  returnEntriesToPool(entries) {
    for (const entry of entries) {
      entry.data = void 0;
      entry.errorContext = void 0;
      entry.correlationId = void 0;
      entry.message = "";
      if (this.entryPool.length < this.maxPoolSize) {
        this.entryPool.push(entry);
      }
    }
  }
  /**
   * Optimized memory management with automatic rotation
   */
  performMemoryManagement() {
    const now = Date.now();
    if (this.logs.length > this.config.maxEntries) {
      this.cleanup();
    }
    if (now - this.lastCleanupTime > this.cleanupInterval) {
      this.periodicCleanup();
      this.lastCleanupTime = now;
    }
  }
  /**
   * Periodic cleanup to manage memory and pool size
   */
  periodicCleanup() {
    if (this.entryPool.length > this.maxPoolSize) {
      this.entryPool.length = this.maxPoolSize;
    }
    const memoryThreshold = this.config.maxEntries * 0.8;
    if (this.logs.length > memoryThreshold) {
      const entriesToRemove = Math.floor(this.config.maxEntries * 0.2);
      const removedEntries = this.logs.splice(0, entriesToRemove);
      this.returnEntriesToPool(removedEntries);
    }
  }
  /**
   * Optimized deep clone for data to prevent reference leaks
   */
  cloneData(data) {
    if (data === null || typeof data !== "object") {
      return data;
    }
    if (data instanceof Date) {
      return new Date(data.getTime());
    }
    if (Array.isArray(data)) {
      return data.map((item) => this.cloneData(item));
    }
    const cloned = {};
    for (const key in data) {
      if (data.hasOwnProperty(key)) {
        cloned[key] = this.cloneData(data[key]);
      }
    }
    return cloned;
  }
  /**
   * Get performance metrics for the debug logger
   */
  getPerformanceMetrics() {
    return {
      totalLogs: this.logCount,
      averageLogTime: this.logCount > 0 ? this.totalLogTime / this.logCount : 0,
      poolSize: this.entryPool.length,
      maxPoolSize: this.maxPoolSize,
      memoryUsage: {
        currentLogs: this.logs.length,
        maxLogs: this.config.maxEntries,
        utilizationPercent: this.logs.length / this.config.maxEntries * 100
      }
    };
  }
  /**
   * Force a memory cleanup and optimization
   */
  optimizeMemory() {
    this.periodicCleanup();
    if (this.logs.length < this.config.maxEntries * 0.5) {
      this.logs = [...this.logs];
    }
    const optimalPoolSize = Math.min(this.maxPoolSize, Math.ceil(this.config.maxEntries * 0.1));
    if (this.entryPool.length > optimalPoolSize) {
      this.entryPool.length = optimalPoolSize;
    }
  }
  /**
   * Optimized JSON stringification with size limits to prevent memory issues
   */
  optimizedStringify(obj, maxDepth = 5, currentDepth = 0) {
    if (currentDepth >= maxDepth) {
      return "[Max Depth Reached]";
    }
    if (obj === null || obj === void 0) {
      return String(obj);
    }
    if (typeof obj !== "object") {
      return typeof obj === "string" ? `"${obj}"` : String(obj);
    }
    const seen = /* @__PURE__ */ new WeakSet();
    try {
      return JSON.stringify(obj, (key, value) => {
        if (typeof value === "object" && value !== null) {
          if (seen.has(value)) {
            return "[Circular Reference]";
          }
          seen.add(value);
        }
        if (typeof value === "string" && value.length > 1e3) {
          return value.substring(0, 1e3) + "... [Truncated]";
        }
        return value;
      }, 2);
    } catch (error) {
      return "[Serialization Failed]";
    }
  }
};

// main.ts
var TaskExtractorPlugin = class extends import_obsidian4.Plugin {
  constructor() {
    super(...arguments);
    this.processingFiles = /* @__PURE__ */ new Set();
    this.serviceCache = /* @__PURE__ */ new Map();
    this.serviceCheckInterval = null;
    this.cloudModelCache = /* @__PURE__ */ new Map();
    this.apiKeyMissingNotified = /* @__PURE__ */ new Set();
    this.fileChangeDebouncer = /* @__PURE__ */ new Map();
    this.debugLogger = null;
  }
  /**
   * Get debug logger instance with lazy initialization.
   * Only creates the logger when debug mode is enabled to avoid overhead.
   */
  getDebugLogger() {
    if (this.settings.debugMode) {
      if (!this.debugLogger) {
        this.debugLogger = new DebugLogger({
          enabled: true,
          maxEntries: this.settings.debugMaxEntries || 1e3
        });
      }
      return this.debugLogger;
    }
    return null;
  }
  async onload() {
    console.log("Loading Task Extractor plugin...");
    await this.loadSettings();
    this.llmProvider = new LLMProviderManager(this.settings, this.getDebugLogger());
    this.taskProcessor = new TaskProcessor(this.app, this.settings, this.llmProvider, this.getDebugLogger());
    this.serviceCache = this.llmProvider.getServiceCache();
    this.cloudModelCache = this.llmProvider.getCloudModelCache();
    this.apiKeyMissingNotified = this.llmProvider.getApiKeyMissingNotified();
    this.processingFiles = this.taskProcessor.getProcessingFiles();
    this.addSettingTab(new ExtractorSettingTab(this.app, this, this.settings, this.llmProvider));
    this.registerEvent(
      this.app.vault.on("create", (file) => {
        if (file instanceof import_obsidian4.TFile) {
          this.debounceFileChange(file);
        }
      })
    );
    if (this.settings.processOnUpdate) {
      this.registerEvent(
        this.app.vault.on("modify", (file) => {
          if (file instanceof import_obsidian4.TFile) {
            this.debounceFileChange(file);
          }
        })
      );
    }
    await this.initializeServices();
    this.scanExistingFiles();
  }
  onunload() {
    console.log("Unloading Task Extractor plugin...");
    if (this.serviceCheckInterval) {
      clearInterval(this.serviceCheckInterval);
      this.serviceCheckInterval = null;
    }
    this.fileChangeDebouncer.forEach((timeout) => clearTimeout(timeout));
    this.fileChangeDebouncer.clear();
    this.cloudModelCache.clear();
    this.apiKeyMissingNotified.clear();
    if (this.debugLogger) {
      this.debugLogger.cleanup();
      this.debugLogger = null;
    }
  }
  async loadSettings() {
    const rawSettings = await this.loadData();
    this.settings = validateSettings(Object.assign({}, DEFAULT_SETTINGS, rawSettings));
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
  // Debounce file changes to prevent rapid processing
  debounceFileChange(file) {
    const existing = this.fileChangeDebouncer.get(file.path);
    if (existing) {
      clearTimeout(existing);
    }
    this.fileChangeDebouncer.set(file.path, setTimeout(() => {
      this.onFileChanged(file);
      this.fileChangeDebouncer.delete(file.path);
    }, 2e3));
  }
  // Delegate to task processor
  async onFileChanged(file) {
    return this.taskProcessor.onFileChanged(file);
  }
  async scanExistingFiles() {
    return this.taskProcessor.scanExistingFiles();
  }
  // Service Detection and Management - delegate to LLM provider
  async initializeServices() {
  }
  async detectServices() {
    return this.llmProvider.detectServices();
  }
  getAvailableServices() {
    return this.llmProvider.getAvailableServices();
  }
  // LLM calls - delegate to provider
  async callLLM(systemPrompt, userPrompt) {
    return this.llmProvider.callLLM(systemPrompt, userPrompt);
  }
  async fetchCloudModels(provider) {
    return this.llmProvider.fetchCloudModels(provider);
  }
  getDefaultModels(provider) {
    return this.llmProvider.getDefaultModels(provider);
  }
};
