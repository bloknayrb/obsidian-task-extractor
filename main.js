/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => TaskExtractorPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian4 = require("obsidian");

// src/types.ts
var DEFAULT_FRONTMATTER_FIELDS = [
  { key: "task", defaultValue: "", type: "text", required: true },
  { key: "status", defaultValue: "inbox", type: "select", options: ["inbox", "next", "waiting", "someday", "done", "cancelled"], required: true },
  { key: "priority", defaultValue: "medium", type: "select", options: ["low", "medium", "high", "urgent"], required: true },
  { key: "due", defaultValue: "", type: "date", required: false },
  { key: "project", defaultValue: "", type: "text", required: false },
  { key: "client", defaultValue: "", type: "text", required: false },
  { key: "created", defaultValue: "{{date}}", type: "date", required: true },
  { key: "tags", defaultValue: "task", type: "text", required: false }
];
var DEFAULT_SETTINGS = {
  provider: "openai",
  apiKey: "",
  model: "gpt-4o-mini",
  // Local LLM settings
  ollamaUrl: "http://localhost:11434",
  lmstudioUrl: "http://localhost:1234",
  localModelRefreshInterval: 5,
  // Processing settings
  tasksFolder: "Tasks",
  linkBack: true,
  processedFrontmatterKey: "taskExtractor.processed",
  ownerName: "Bryan Kolb",
  processOnUpdate: false,
  triggerTypes: ["email", "meetingnote", "meeting note", "meeting notes"],
  triggerFrontmatterField: "Type",
  // default to "Type" for backward compatibility
  // Customizable frontmatter
  frontmatterFields: DEFAULT_FRONTMATTER_FIELDS,
  customPrompt: "",
  // Advanced settings
  maxTokens: 800,
  temperature: 0,
  timeout: 30,
  retries: 3,
  // Debug settings
  debugMode: false,
  debugMaxEntries: 1e3
};
function validateSettings(settings) {
  const validated = { ...DEFAULT_SETTINGS };
  if (settings.provider && ["openai", "anthropic", "ollama", "lmstudio"].includes(settings.provider)) {
    validated.provider = settings.provider;
  }
  if (typeof settings.apiKey === "string")
    validated.apiKey = settings.apiKey;
  if (typeof settings.model === "string")
    validated.model = settings.model;
  if (typeof settings.ollamaUrl === "string")
    validated.ollamaUrl = settings.ollamaUrl;
  if (typeof settings.lmstudioUrl === "string")
    validated.lmstudioUrl = settings.lmstudioUrl;
  if (typeof settings.tasksFolder === "string" && settings.tasksFolder.trim()) {
    validated.tasksFolder = settings.tasksFolder.trim();
  }
  if (typeof settings.ownerName === "string" && settings.ownerName.trim()) {
    validated.ownerName = settings.ownerName.trim();
  }
  if (typeof settings.customPrompt === "string")
    validated.customPrompt = settings.customPrompt;
  if (typeof settings.processedFrontmatterKey === "string") {
    const key = settings.processedFrontmatterKey.trim();
    const parts = key.split(".");
    const yamlKeyPattern = /^[a-zA-Z_][a-zA-Z0-9_-]*$/;
    const isValid = parts.every((part) => part && yamlKeyPattern.test(part));
    if (isValid) {
      validated.processedFrontmatterKey = key;
    }
  }
  if (typeof settings.triggerFrontmatterField === "string") {
    const field = settings.triggerFrontmatterField.trim();
    const yamlKeyPattern = /^[a-zA-Z_][a-zA-Z0-9_.-]*$/;
    if (field && yamlKeyPattern.test(field) && !field.includes("..") && !field.startsWith(".") && !field.endsWith(".")) {
      validated.triggerFrontmatterField = field;
    }
  }
  if (typeof settings.linkBack === "boolean")
    validated.linkBack = settings.linkBack;
  if (typeof settings.processOnUpdate === "boolean")
    validated.processOnUpdate = settings.processOnUpdate;
  if (Array.isArray(settings.triggerTypes)) {
    const validTypes = settings.triggerTypes.filter((t) => typeof t === "string" && t.trim().length > 0).map((t) => t.trim());
    if (validTypes.length > 0) {
      validated.triggerTypes = validTypes;
    }
  }
  if (Array.isArray(settings.frontmatterFields)) {
    const validFields = settings.frontmatterFields.filter(
      (f) => f && typeof f.key === "string" && f.key.trim().length > 0 && typeof f.defaultValue === "string" && typeof f.type === "string" && ["text", "date", "select", "boolean"].includes(f.type) && typeof f.required === "boolean"
    );
    if (validFields.length > 0) {
      validated.frontmatterFields = validFields;
    }
  }
  if (typeof settings.localModelRefreshInterval === "number" && !isNaN(settings.localModelRefreshInterval)) {
    validated.localModelRefreshInterval = Math.max(1, Math.min(60, settings.localModelRefreshInterval));
  }
  if (typeof settings.maxTokens === "number" && !isNaN(settings.maxTokens)) {
    validated.maxTokens = Math.max(100, Math.min(2e3, settings.maxTokens));
  }
  if (typeof settings.temperature === "number" && !isNaN(settings.temperature)) {
    validated.temperature = Math.max(0, Math.min(1, settings.temperature));
  }
  if (typeof settings.timeout === "number" && !isNaN(settings.timeout)) {
    validated.timeout = Math.max(10, Math.min(120, settings.timeout));
  }
  if (typeof settings.retries === "number" && !isNaN(settings.retries)) {
    validated.retries = Math.max(1, Math.min(5, settings.retries));
  }
  if (typeof settings.debugMode === "boolean") {
    validated.debugMode = settings.debugMode;
  }
  if (typeof settings.debugMaxEntries === "number" && !isNaN(settings.debugMaxEntries)) {
    validated.debugMaxEntries = Math.max(100, Math.min(1e4, settings.debugMaxEntries));
  }
  return validated;
}

// src/llm-providers.ts
var import_obsidian = require("obsidian");
var LLMProviderManager = class {
  constructor(settings) {
    this.settings = settings;
    this.serviceCache = /* @__PURE__ */ new Map();
    this.cloudModelCache = /* @__PURE__ */ new Map();
    this.apiKeyMissingNotified = /* @__PURE__ */ new Set();
  }
  // Get service with 30-minute cache TTL
  async getService(provider) {
    const cached = this.serviceCache.get(provider);
    const now = Date.now();
    const cacheValidMs = 30 * 60 * 1e3;
    if (cached && now - cached.lastChecked < cacheValidMs) {
      return cached;
    }
    return await this.detectSingleService(provider);
  }
  // Detect a single service instead of all services
  async detectSingleService(provider) {
    var _a, _b;
    const now = Date.now();
    if (provider === "ollama") {
      const service = {
        name: "ollama",
        url: this.settings.ollamaUrl,
        available: false,
        models: [],
        lastChecked: now
      };
      try {
        const rawResponse = await (0, import_obsidian.requestUrl)({
          url: `${this.settings.ollamaUrl}/api/tags`,
          method: "GET"
        });
        const response = this.adaptRequestUrlResponse(rawResponse);
        if (response.ok) {
          const data = await response.json();
          service.available = true;
          service.models = ((_a = data.models) == null ? void 0 : _a.map((m) => m.name)) || [];
        }
      } catch (error) {
        console.log("Ollama not available:", error.message);
      }
      this.serviceCache.set("ollama", service);
      return service;
    }
    if (provider === "lmstudio") {
      const service = {
        name: "lmstudio",
        url: this.settings.lmstudioUrl,
        available: false,
        models: [],
        lastChecked: now
      };
      try {
        const rawResponse = await (0, import_obsidian.requestUrl)({
          url: `${this.settings.lmstudioUrl}/v1/models`,
          method: "GET"
        });
        const response = this.adaptRequestUrlResponse(rawResponse);
        if (response.ok) {
          const data = await response.json();
          service.available = true;
          service.models = ((_b = data.data) == null ? void 0 : _b.map((m) => m.id)) || [];
        }
      } catch (error) {
        console.log("LM Studio not available:", error.message);
      }
      this.serviceCache.set("lmstudio", service);
      return service;
    }
    return null;
  }
  // Legacy method for backward compatibility
  async detectServices() {
    await this.getService("ollama");
    await this.getService("lmstudio");
    return this.serviceCache;
  }
  getAvailableServices() {
    return Array.from(this.serviceCache.values()).filter((s) => s.available);
  }
  // Provider-agnostic LLM call with fallback support
  async callLLM(systemPrompt, userPrompt) {
    const provider = this.settings.provider;
    if (["openai", "anthropic"].includes(provider) && !this.settings.apiKey) {
      const notificationKey = `${provider}-no-api-key`;
      if (!this.apiKeyMissingNotified.has(notificationKey)) {
        console.warn(`Task Extractor: ${provider.toUpperCase()} API key not configured in plugin settings`);
        this.apiKeyMissingNotified.add(notificationKey);
      }
      return null;
    }
    if (this.settings.apiKey) {
      this.apiKeyMissingNotified.delete(`${provider}-no-api-key`);
    }
    for (let attempt = 0; attempt < this.settings.retries; attempt++) {
      try {
        let result = null;
        switch (provider) {
          case "openai":
            result = await this.callOpenAI(systemPrompt, userPrompt);
            break;
          case "anthropic":
            result = await this.callAnthropic(systemPrompt, userPrompt);
            break;
          case "ollama":
            result = await this.callOllama(systemPrompt, userPrompt);
            break;
          case "lmstudio":
            result = await this.callLMStudio(systemPrompt, userPrompt);
            break;
          default:
            throw new Error(`Unsupported provider: ${provider}`);
        }
        if (result)
          return result;
      } catch (error) {
        console.warn(`Attempt ${attempt + 1} failed for ${provider}:`, error.message);
        if (attempt === this.settings.retries - 1) {
          if (["ollama", "lmstudio"].includes(provider)) {
            return await this.tryLocalFallback(systemPrompt, userPrompt);
          }
        } else {
          await this.delay(1e3 * (attempt + 1));
        }
      }
    }
    return null;
  }
  async tryLocalFallback(systemPrompt, userPrompt) {
    const availableServices = this.getAvailableServices();
    for (const service of availableServices) {
      if (service.name === this.settings.provider)
        continue;
      try {
        console.log(`Trying fallback to ${service.name}`);
        if (service.name === "ollama") {
          return await this.callOllama(systemPrompt, userPrompt);
        } else if (service.name === "lmstudio") {
          return await this.callLMStudio(systemPrompt, userPrompt);
        }
      } catch (error) {
        console.warn(`Fallback to ${service.name} failed:`, error.message);
      }
    }
    console.warn("Task Extractor: All LLM services failed. Check your configuration.");
    return null;
  }
  async callOpenAI(systemPrompt, userPrompt) {
    var _a, _b, _c;
    const endpoint = "https://api.openai.com/v1/chat/completions";
    const body = {
      model: this.settings.model || "gpt-4o-mini",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt }
      ],
      temperature: this.settings.temperature,
      max_tokens: this.settings.maxTokens
    };
    try {
      const rawResp = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "POST",
        headers: {
          "Authorization": `Bearer ${this.settings.apiKey}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify(body)
      });
      const resp = this.adaptRequestUrlResponse(rawResp);
      if (!resp.ok) {
        const text = await resp.text();
        console.error("OpenAI error", resp.status, text);
        throw new Error(`OpenAI API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      return ((_c = (_b = (_a = json == null ? void 0 : json.choices) == null ? void 0 : _a[0]) == null ? void 0 : _b.message) == null ? void 0 : _c.content) || null;
    } catch (e) {
      console.error("callOpenAI error", e);
      throw e;
    }
  }
  async callAnthropic(systemPrompt, userPrompt) {
    var _a, _b;
    const endpoint = "https://api.anthropic.com/v1/messages";
    try {
      const rawResp = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "POST",
        headers: {
          "x-api-key": this.settings.apiKey,
          "Content-Type": "application/json",
          "anthropic-version": "2023-06-01"
        },
        body: JSON.stringify({
          model: this.settings.model || "claude-3-sonnet-20240229",
          max_tokens: this.settings.maxTokens,
          temperature: this.settings.temperature,
          system: systemPrompt,
          messages: [{
            role: "user",
            content: userPrompt
          }]
        })
      });
      const resp = this.adaptRequestUrlResponse(rawResp);
      if (!resp.ok) {
        const text = await resp.text();
        console.error("Anthropic error", resp.status, text);
        throw new Error(`Anthropic API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      return ((_b = (_a = json == null ? void 0 : json.content) == null ? void 0 : _a[0]) == null ? void 0 : _b.text) || null;
    } catch (e) {
      console.error("callAnthropic error", e);
      throw e;
    }
  }
  async callOllama(systemPrompt, userPrompt) {
    var _a;
    const service = await this.getService("ollama");
    if (!(service == null ? void 0 : service.available) || !service.models.length) {
      throw new Error("Ollama service not available or no models loaded");
    }
    const model = service.models.includes(this.settings.model) ? this.settings.model : service.models[0];
    const endpoint = `${this.settings.ollamaUrl}/api/chat`;
    try {
      const rawResp = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model,
          messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: userPrompt }
          ],
          stream: false,
          options: {
            temperature: this.settings.temperature,
            num_predict: this.settings.maxTokens
          }
        })
      });
      const resp = this.adaptRequestUrlResponse(rawResp);
      if (!resp.ok) {
        const text = await resp.text();
        console.error("Ollama error", resp.status, text);
        throw new Error(`Ollama API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      return ((_a = json == null ? void 0 : json.message) == null ? void 0 : _a.content) || null;
    } catch (e) {
      console.error("callOllama error", e);
      throw e;
    }
  }
  async callLMStudio(systemPrompt, userPrompt) {
    var _a, _b, _c;
    const service = await this.getService("lmstudio");
    if (!(service == null ? void 0 : service.available) || !service.models.length) {
      throw new Error("LM Studio service not available or no models loaded");
    }
    const model = service.models.includes(this.settings.model) ? this.settings.model : service.models[0];
    const endpoint = `${this.settings.lmstudioUrl}/v1/chat/completions`;
    try {
      const rawResp = await (0, import_obsidian.requestUrl)({
        url: endpoint,
        method: "POST",
        headers: {
          "Authorization": "Bearer lm-studio",
          // Placeholder auth
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model,
          messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: userPrompt }
          ],
          temperature: this.settings.temperature,
          max_tokens: this.settings.maxTokens
        })
      });
      const resp = this.adaptRequestUrlResponse(rawResp);
      if (!resp.ok) {
        const text = await resp.text();
        console.error("LM Studio error", resp.status, text);
        throw new Error(`LM Studio API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      return ((_c = (_b = (_a = json == null ? void 0 : json.choices) == null ? void 0 : _a[0]) == null ? void 0 : _b.message) == null ? void 0 : _c.content) || null;
    } catch (e) {
      console.error("callLMStudio error", e);
      throw e;
    }
  }
  // Fetch available models for cloud providers
  async fetchCloudModels(provider) {
    if (!this.settings.apiKey) {
      return [];
    }
    const cacheKey = `${provider}-${this.settings.apiKey.slice(-4)}`;
    if (this.cloudModelCache.has(cacheKey)) {
      return this.cloudModelCache.get(cacheKey) || [];
    }
    try {
      if (provider === "openai") {
        return await this.fetchOpenAIModels();
      } else if (provider === "anthropic") {
        return await this.fetchAnthropicModels();
      }
    } catch (error) {
      console.warn(`Failed to fetch ${provider} models:`, error.message);
      return this.getDefaultModels(provider);
    }
    return [];
  }
  async fetchOpenAIModels() {
    var _a, _b, _c;
    const rawResponse = await (0, import_obsidian.requestUrl)({
      url: "https://api.openai.com/v1/models",
      method: "GET",
      headers: {
        "Authorization": `Bearer ${this.settings.apiKey}`,
        "Content-Type": "application/json"
      }
    });
    const response = this.adaptRequestUrlResponse(rawResponse);
    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }
    const data = await response.json();
    const models = ((_c = (_b = (_a = data.data) == null ? void 0 : _a.filter((model) => model.id.includes("gpt") && !model.id.includes("instruct"))) == null ? void 0 : _b.map((model) => model.id)) == null ? void 0 : _c.sort()) || [];
    const cacheKey = `openai-${this.settings.apiKey.slice(-4)}`;
    this.cloudModelCache.set(cacheKey, models);
    return models.length > 0 ? models : this.getDefaultModels("openai");
  }
  async fetchAnthropicModels() {
    const knownModels = [
      "claude-3-5-sonnet-20241022",
      "claude-3-5-haiku-20241022",
      "claude-3-opus-20240229",
      "claude-3-sonnet-20240229",
      "claude-3-haiku-20240307"
    ];
    const cacheKey = `anthropic-${this.settings.apiKey.slice(-4)}`;
    this.cloudModelCache.set(cacheKey, knownModels);
    return knownModels;
  }
  getDefaultModels(provider) {
    const defaults = {
      openai: ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
      anthropic: ["claude-3-5-sonnet-20241022", "claude-3-haiku-20240307"],
      ollama: ["llama3.2", "mistral", "codellama"],
      lmstudio: ["local-model"]
    };
    return defaults[provider] || [];
  }
  // Utility methods
  delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
  createTimeoutSignal(ms) {
    const controller = new AbortController();
    setTimeout(() => controller.abort(), ms);
    return controller.signal;
  }
  // Cleanup method
  cleanup() {
    this.cloudModelCache.clear();
    this.apiKeyMissingNotified.clear();
    this.serviceCache.clear();
  }
  // Helper to adapt requestUrl response to fetch-like interface
  adaptRequestUrlResponse(response) {
    return {
      ok: response.status >= 200 && response.status < 300,
      status: response.status,
      statusText: response.status.toString(),
      json: async () => response.json,
      text: async () => response.text
    };
  }
  // Methods for backward compatibility
  getServiceCache() {
    return this.serviceCache;
  }
  getCloudModelCache() {
    return this.cloudModelCache;
  }
  getApiKeyMissingNotified() {
    return this.apiKeyMissingNotified;
  }
};

// src/task-processor.ts
var import_obsidian2 = require("obsidian");
var TaskProcessor = class {
  constructor(app, settings, llmProvider, debugLogger) {
    this.app = app;
    this.settings = settings;
    this.llmProvider = llmProvider;
    this.debugLogger = debugLogger;
    this.processingFiles = /* @__PURE__ */ new Set();
    this.fileChangeDebouncer = /* @__PURE__ */ new Map();
    this.processingQueue = /* @__PURE__ */ new Map();
  }
  /**
   * Conditional logging helper to ensure zero overhead when debug mode is disabled
   */
  log(level, category, message, data, correlationId) {
    var _a;
    if ((_a = this.debugLogger) == null ? void 0 : _a.isEnabled()) {
      this.debugLogger.log(level, category, message, data, correlationId);
    }
  }
  /**
   * Start a new operation for correlation tracking
   */
  startOperation(category, message, data) {
    var _a;
    if ((_a = this.debugLogger) == null ? void 0 : _a.isEnabled()) {
      return this.debugLogger.startOperation(category, message, data);
    }
    return void 0;
  }
  // Debounce file changes to prevent rapid processing
  debounceFileChange(file, callback) {
    const existing = this.fileChangeDebouncer.get(file.path);
    if (existing) {
      clearTimeout(existing);
    }
    this.fileChangeDebouncer.set(file.path, setTimeout(() => {
      callback(file);
      this.fileChangeDebouncer.delete(file.path);
    }, 2e3));
  }
  // When a file is created or modified
  async onFileChanged(file) {
    var _a, _b, _c;
    if (file.extension !== "md") {
      this.log("info", "file-processing", "File skipped: not a markdown file", {
        filePath: file.path,
        extension: file.extension
      });
      return;
    }
    const correlationId = this.startOperation("file-processing", "Processing file", {
      filePath: file.path
    });
    const queueStatus = this.processingQueue.get(file.path);
    if ((queueStatus == null ? void 0 : queueStatus.status) === "processing" || this.processingFiles.has(file.path)) {
      this.log("info", "file-processing", "File skipped: already being processed", {
        filePath: file.path,
        queueStatus: queueStatus == null ? void 0 : queueStatus.status,
        inProcessingSet: this.processingFiles.has(file.path)
      }, correlationId);
      return;
    }
    const processingStatus = {
      status: "queued",
      startTime: Date.now()
    };
    processingStatus.timeout = setTimeout(() => {
      console.warn(`TaskExtractor: File processing timeout for ${file.path}`);
      this.cleanupFileProcessing(file.path);
    }, 3e4);
    this.processingQueue.set(file.path, processingStatus);
    this.processingFiles.add(file.path);
    processingStatus.status = "processing";
    try {
      const cache = this.app.metadataCache.getFileCache(file);
      const front = cache == null ? void 0 : cache.frontmatter;
      if (!front) {
        this.log("info", "file-processing", "File skipped: no frontmatter found", {
          filePath: file.path
        }, correlationId);
        return;
      }
      this.log("info", "file-processing", "File has frontmatter, validating", {
        filePath: file.path,
        frontmatterKeys: Object.keys(front)
      }, correlationId);
      if (!this.settings.triggerTypes || !Array.isArray(this.settings.triggerTypes) || this.settings.triggerTypes.length === 0) {
        console.warn("TaskExtractor: Invalid trigger types configuration, skipping processing");
        this.log("error", "validation", "Invalid trigger types configuration", {
          filePath: file.path,
          triggerTypes: this.settings.triggerTypes
        }, correlationId);
        this.processingFiles.delete(file.path);
        return;
      }
      const processedKey = this.settings.processedFrontmatterKey || "taskExtractor.processed";
      const processedValue = this.getFrontmatterValue(front, processedKey);
      if (processedValue === true || processedValue === "true") {
        this.log("info", "file-processing", "File skipped: already processed", {
          filePath: file.path,
          processedKey,
          processedValue
        }, correlationId);
        return;
      }
      const frontmatterField = this.validateFrontmatterField(this.settings.triggerFrontmatterField);
      const typeRaw = this.getFrontmatterValue(front, frontmatterField) || "";
      const type = ("" + typeRaw).toLowerCase();
      const accepted = this.settings.triggerTypes.map((t) => t.toLowerCase());
      this.log("info", "file-processing", "Checking trigger type match", {
        filePath: file.path,
        frontmatterField,
        typeFound: type,
        acceptedTypes: accepted,
        matches: accepted.includes(type)
      }, correlationId);
      if (!accepted.includes(type)) {
        this.log("info", "file-processing", "File skipped: trigger type not matched", {
          filePath: file.path,
          typeFound: type,
          acceptedTypes: accepted
        }, correlationId);
        return;
      }
      if (!this.settings.ownerName || this.settings.ownerName.trim().length === 0) {
        console.warn("TaskExtractor: Owner name not configured, skipping processing");
        this.log("error", "validation", "Owner name not configured", {
          filePath: file.path,
          ownerName: this.settings.ownerName
        }, correlationId);
        this.processingFiles.delete(file.path);
        return;
      }
      const content = await this.app.vault.read(file);
      this.log("info", "file-processing", "File content read, proceeding to task extraction", {
        filePath: file.path,
        contentLength: content.length
      }, correlationId);
      const extraction = await this.extractTaskFromContent(content, file.path, correlationId);
      if (extraction && extraction.found) {
        this.log("info", "file-processing", "Tasks found, proceeding to task creation", {
          filePath: file.path,
          tasksFound: "tasks" in extraction ? (_a = extraction.tasks) == null ? void 0 : _a.length : 1
        }, correlationId);
        await this.handleTaskExtraction(extraction, file, correlationId);
      } else {
        this.log("info", "file-processing", "No tasks found in file", {
          filePath: file.path
        }, correlationId);
      }
      await this.markFileProcessed(file, correlationId);
      if (this.processingQueue.has(file.path)) {
        this.processingQueue.get(file.path).status = "completed";
      }
      this.log("info", "file-processing", "File processing completed successfully", {
        filePath: file.path,
        processingTime: Date.now() - (((_b = this.processingQueue.get(file.path)) == null ? void 0 : _b.startTime) || Date.now())
      }, correlationId);
    } catch (err) {
      console.error("TaskExtractor error", err);
      new import_obsidian2.Notice("Task Extractor: error processing file \u2014 see console");
      this.log("error", "error", "File processing failed with error", {
        filePath: file.path,
        error: err instanceof Error ? err.message : String(err),
        stack: err instanceof Error ? err.stack : void 0,
        processingTime: Date.now() - (((_c = this.processingQueue.get(file.path)) == null ? void 0 : _c.startTime) || Date.now())
      }, correlationId);
      if (this.processingQueue.has(file.path)) {
        this.processingQueue.get(file.path).status = "failed";
      }
    } finally {
      this.cleanupFileProcessing(file.path);
    }
  }
  // Centralized cleanup method for atomic processing
  cleanupFileProcessing(filePath) {
    const status = this.processingQueue.get(filePath);
    if (status == null ? void 0 : status.timeout) {
      clearTimeout(status.timeout);
    }
    this.processingQueue.delete(filePath);
    this.processingFiles.delete(filePath);
  }
  // scan vault once on load for unprocessed matching notes
  async scanExistingFiles() {
    const files = this.getUnprocessedFiles();
    const batches = this.chunkArray(files, 5);
    for (const batch of batches) {
      await Promise.all(batch.map((f) => this.onFileChanged(f)));
      await this.delay(100);
    }
  }
  // Get list of unprocessed files that match trigger criteria
  getUnprocessedFiles() {
    const files = this.app.vault.getMarkdownFiles();
    const unprocessedFiles = [];
    for (const f of files) {
      const cache = this.app.metadataCache.getFileCache(f);
      const front = cache == null ? void 0 : cache.frontmatter;
      if (!front)
        continue;
      const frontmatterField = this.validateFrontmatterField(this.settings.triggerFrontmatterField);
      const typeRaw = this.getFrontmatterValue(front, frontmatterField) || "";
      const type = ("" + typeRaw).toLowerCase();
      const accepted = this.settings.triggerTypes.map((t) => t.toLowerCase());
      const processedValue = this.getFrontmatterValue(front, this.settings.processedFrontmatterKey);
      if (accepted.includes(type) && !(processedValue === true || processedValue === "true")) {
        unprocessedFiles.push(f);
      }
    }
    return unprocessedFiles;
  }
  // Utility function to chunk array into smaller batches
  chunkArray(array, size) {
    const chunks = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
  // Utility function for delays
  delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
  getFrontmatterValue(front, key) {
    if (!front)
      return void 0;
    if (key.includes(".")) {
      const parts = key.split(".");
      let cur = front;
      for (const p of parts) {
        if (!cur)
          return void 0;
        cur = cur[p];
      }
      return cur;
    }
    return front[key];
  }
  async markFileProcessed(file, correlationId) {
    if (!this.settings.processedFrontmatterKey) {
      this.log("info", "file-processing", "Skipping processed marker: no processed frontmatter key configured", {
        filePath: file.path
      }, correlationId);
      return;
    }
    try {
      await this.app.fileManager.processFrontMatter(file, (frontmatter) => {
        const keys = this.settings.processedFrontmatterKey.split(".");
        let current = frontmatter;
        for (let i = 0; i < keys.length - 1; i++) {
          const key = keys[i];
          if (!current[key] || typeof current[key] !== "object") {
            current[key] = {};
          }
          current = current[key];
        }
        current[keys[keys.length - 1]] = true;
      });
      this.log("info", "file-processing", "File marked as processed successfully", {
        filePath: file.path,
        processedKey: this.settings.processedFrontmatterKey
      }, correlationId);
    } catch (e) {
      console.warn("Failed to mark file processed with official API:", e);
      this.log("warn", "file-processing", "Failed to mark file processed with official API, trying fallback", {
        filePath: file.path,
        error: e instanceof Error ? e.message : String(e)
      }, correlationId);
      await this.markFileProcessedFallback(file, correlationId);
    }
  }
  // Fallback method using the previous implementation
  async markFileProcessedFallback(file, correlationId) {
    try {
      const content = await this.app.vault.read(file);
      const fmMatch = content.match(/^---\n([\s\S]*?)\n---/);
      let newContent = content;
      if (fmMatch) {
        const fm = fmMatch[1];
        const processedKey = this.settings.processedFrontmatterKey;
        if (!new RegExp("^" + processedKey.replace(".", "\\.") + ":", "m").test(fm)) {
          const lines = fm.split("\n");
          lines.push(`${processedKey}: true`);
          const updatedFm = lines.join("\n");
          newContent = content.replace(fmMatch[0], `---
${updatedFm}
---`);
          await this.app.vault.modify(file, newContent);
        }
      } else {
        const processedKey = this.settings.processedFrontmatterKey;
        newContent = `---
${processedKey}: true
---

` + content;
        await this.app.vault.modify(file, newContent);
      }
      this.log("info", "file-processing", "File marked as processed using fallback method", {
        filePath: file.path,
        processedKey: this.settings.processedFrontmatterKey
      }, correlationId);
    } catch (e) {
      console.warn("Failed to mark file processed with fallback method:", e);
      this.log("error", "file-processing", "Failed to mark file processed with fallback method", {
        filePath: file.path,
        error: e instanceof Error ? e.message : String(e)
      }, correlationId);
    }
  }
  // Shared method for constructing prompts
  buildExtractionPrompt(sourcePath, content) {
    const basePrompt = this.settings.customPrompt || `You are a task extraction specialist. Extract actionable tasks from emails and meeting notes following these strict rules:

EXTRACTION RULES:
- Extract ONLY concrete, actionable tasks explicitly stated or clearly implied
- Use null for uncertain/missing information - DO NOT GUESS
- Extract tasks only for the specified person: ${this.settings.ownerName} (exact name)
- If no clear tasks exist, return {"found": false, "tasks": []}

PRIORITY GUIDELINES:
- high: explicit urgency/deadline mentioned
- medium: standard requests without time pressure  
- low: optional/background items

VALIDATION CONSTRAINTS:
- task_title: 6-100 characters, actionable phrasing
- task_details: max 300 characters, concrete description
- due_date: YYYY-MM-DD format only if explicitly mentioned
- source_excerpt: exact quote (max 150 chars) justifying extraction

Return valid JSON only. Be conservative - accuracy over completeness.`;
    const fieldDescriptions = this.settings.frontmatterFields.filter((f) => f.required || f.key === "task_title" || f.key === "task_details").map((f) => {
      var _a;
      if (f.key === "task" || f.key === "task_title")
        return "- task_title: short (6-100 words) actionable title";
      if (f.key === "task_details")
        return "- task_details: 1-3 sentences describing what to do and any context";
      if (f.key === "due")
        return "- due_date: ISO date YYYY-MM-DD if explicitly present in the text, otherwise null";
      if (f.key === "priority")
        return `- priority: ${((_a = f.options) == null ? void 0 : _a.join("|")) || "high|medium|low"} (choose best match)`;
      if (f.key === "project")
        return "- project: project name if mentioned, otherwise null";
      if (f.key === "client")
        return "- client: client name if mentioned, otherwise null";
      return `- ${f.key}: ${f.defaultValue || "appropriate value based on context"}`;
    });
    const system = `${basePrompt}

When tasks are found, return JSON in this format:
{
  "found": true,
  "tasks": [
    {
      ${fieldDescriptions.join(",\n      ")},
      "source_excerpt": "exact quote from source (max 150 chars)",
      "confidence": "high|medium|low"
    }
  ],
  "confidence": "high|medium|low"
}

When no tasks found, return: {"found": false, "tasks": []}`;
    const user = `SOURCE_PATH: ${sourcePath}
---BEGIN NOTE---
${content}
---END NOTE---`;
    return { system, user };
  }
  // New method for multi-task extraction
  async extractMultipleTasksFromContent(content, sourcePath, correlationId) {
    var _a;
    const { system, user } = this.buildExtractionPrompt(sourcePath, content);
    this.log("info", "llm-call", "LLM prompt constructed for multi-task extraction", {
      filePath: sourcePath,
      systemPromptLength: system.length,
      userPromptLength: user.length,
      contentLength: content.length
    }, correlationId);
    try {
      const raw = await this.llmProvider.callLLM(system, user);
      this.log("info", "llm-call", "LLM response received for multi-task extraction", {
        filePath: sourcePath,
        responseLength: (raw == null ? void 0 : raw.length) || 0,
        responsePreview: (raw == null ? void 0 : raw.substring(0, 200)) || "null"
      }, correlationId);
      const parsed = this.safeParseJSON(raw);
      if (!parsed) {
        this.log("warn", "llm-call", "Failed to parse LLM response as JSON for multi-task extraction", {
          filePath: sourcePath,
          rawResponse: raw
        }, correlationId);
        return { found: false, tasks: [] };
      }
      this.log("info", "llm-call", "LLM response parsed successfully for multi-task extraction", {
        filePath: sourcePath,
        parsedStructure: Object.keys(parsed),
        found: parsed.found || false,
        tasksCount: ((_a = parsed.tasks) == null ? void 0 : _a.length) || 0
      }, correlationId);
      if ("tasks" in parsed && Array.isArray(parsed.tasks)) {
        return parsed;
      }
      if ("found" in parsed && parsed.found) {
        return {
          found: true,
          tasks: [{
            task_title: parsed.task_title || "Unspecified task",
            task_details: parsed.task_details || "",
            due_date: parsed.due_date || null,
            priority: parsed.priority || "medium",
            project: parsed.project || null,
            client: parsed.client || null,
            source_excerpt: parsed.source_excerpt || "",
            confidence: parsed.confidence || "medium"
          }]
        };
      }
      return { found: false, tasks: [] };
    } catch (e) {
      console.error("extractMultipleTasksFromContent error", e);
      this.log("error", "llm-call", "Multi-task extraction failed with error", {
        filePath: sourcePath,
        error: e instanceof Error ? e.message : String(e),
        stack: e instanceof Error ? e.stack : void 0
      }, correlationId);
      return { found: false, tasks: [] };
    }
  }
  // Handle task extraction results (both single and multi-task)
  async handleTaskExtraction(extraction, sourceFile, correlationId) {
    try {
      if ("tasks" in extraction && Array.isArray(extraction.tasks)) {
        this.log("info", "task-creation", "Processing multi-task extraction result", {
          filePath: sourceFile.path,
          tasksCount: extraction.tasks.length
        }, correlationId);
        let createdCount = 0;
        for (const task of extraction.tasks) {
          try {
            await this.createTaskNote(task, sourceFile, correlationId);
            createdCount++;
          } catch (error) {
            console.error(`Failed to create task note for: ${task.task_title}`, error);
            this.log("error", "task-creation", "Failed to create individual task note", {
              filePath: sourceFile.path,
              taskTitle: task.task_title,
              error: error instanceof Error ? error.message : String(error)
            }, correlationId);
          }
        }
        this.log("info", "task-creation", "Multi-task creation completed", {
          filePath: sourceFile.path,
          totalTasks: extraction.tasks.length,
          createdCount,
          failedCount: extraction.tasks.length - createdCount
        }, correlationId);
        if (createdCount > 0) {
          new import_obsidian2.Notice(`Task Extractor: created ${createdCount} task note${createdCount !== 1 ? "s" : ""}`);
        }
      } else {
        this.log("info", "task-creation", "Processing single-task extraction result", {
          filePath: sourceFile.path,
          taskTitle: extraction.task_title
        }, correlationId);
        await this.createTaskNote(extraction, sourceFile, correlationId);
        new import_obsidian2.Notice(`Task Extractor: created task "${extraction.task_title}"`);
      }
    } catch (error) {
      console.error("Error handling task extraction:", error);
      this.log("error", "task-creation", "Task extraction handling failed", {
        filePath: sourceFile.path,
        error: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : void 0
      }, correlationId);
      new import_obsidian2.Notice("Task Extractor: error creating task notes \u2014 see console");
    }
  }
  // Compose prompt, call LLM, and parse response (legacy method for backward compatibility)
  async extractTaskFromContent(content, sourcePath, correlationId) {
    var _a;
    const { system, user } = this.buildExtractionPrompt(sourcePath, content);
    this.log("info", "llm-call", "LLM prompt constructed for task extraction", {
      filePath: sourcePath,
      systemPromptLength: system.length,
      userPromptLength: user.length,
      contentLength: content.length
    }, correlationId);
    try {
      const raw = await this.llmProvider.callLLM(system, user);
      this.log("info", "llm-call", "LLM response received for task extraction", {
        filePath: sourcePath,
        responseLength: (raw == null ? void 0 : raw.length) || 0,
        responsePreview: (raw == null ? void 0 : raw.substring(0, 200)) || "null"
      }, correlationId);
      const parsed = this.safeParseJSON(raw);
      if (!parsed) {
        this.log("warn", "llm-call", "Failed to parse LLM response as JSON", {
          filePath: sourcePath,
          rawResponse: raw
        }, correlationId);
        return { found: false };
      }
      this.log("info", "llm-call", "LLM response parsed successfully", {
        filePath: sourcePath,
        parsedStructure: Object.keys(parsed),
        found: parsed.found || false,
        tasksCount: ((_a = parsed.tasks) == null ? void 0 : _a.length) || (parsed.found ? 1 : 0)
      }, correlationId);
      if (parsed.tasks && Array.isArray(parsed.tasks)) {
        if (parsed.tasks.length > 0) {
          const firstTask = parsed.tasks[0];
          return {
            found: true,
            task_title: firstTask.task_title || "Unspecified task",
            task_details: firstTask.task_details || "",
            due_date: firstTask.due_date || null,
            priority: firstTask.priority || "medium",
            source_excerpt: firstTask.source_excerpt || "",
            ...firstTask
            // Include any additional extracted fields
          };
        } else {
          return { found: false };
        }
      }
      if (!parsed.found)
        return { found: false };
      return {
        found: true,
        task_title: parsed.task_title || parsed.title || "Unspecified task",
        task_details: parsed.task_details || parsed.details || "",
        due_date: parsed.due_date || null,
        priority: parsed.priority || "medium",
        source_excerpt: parsed.source_excerpt || "",
        ...parsed
        // Include any additional extracted fields
      };
    } catch (e) {
      console.error("extractTaskFromContent error", e);
      this.log("error", "llm-call", "Task extraction failed with error", {
        filePath: sourcePath,
        error: e instanceof Error ? e.message : String(e),
        stack: e instanceof Error ? e.stack : void 0
      }, correlationId);
      return { found: false };
    }
  }
  safeParseJSON(text) {
    if (!text)
      return null;
    let parsed = null;
    try {
      parsed = JSON.parse(text);
    } catch (e) {
      const m = text.match(/\{[\s\S]*\}/);
      if (m) {
        try {
          parsed = JSON.parse(m[0]);
        } catch (e2) {
          const fixed = m[0].replace(/'/g, '"');
          try {
            parsed = JSON.parse(fixed);
          } catch (e3) {
            return null;
          }
        }
      } else {
        return null;
      }
    }
    if (!parsed || typeof parsed !== "object")
      return null;
    return this.validateAndNormalizeParsedResult(parsed);
  }
  validateAndNormalizeParsedResult(data) {
    if (typeof data !== "object" || data === null) {
      this.log("warn", "validation", "Parsed data is not an object", {
        dataType: typeof data,
        data
      });
      return null;
    }
    if (data.hasOwnProperty("tasks") && Array.isArray(data.tasks)) {
      const validTasks = [];
      for (const task of data.tasks) {
        if (this.isValidTask(task)) {
          validTasks.push({
            task_title: task.task_title || "Unspecified task",
            task_details: task.task_details || "",
            due_date: task.due_date || null,
            priority: task.priority || "medium",
            project: task.project || null,
            client: task.client || null,
            source_excerpt: task.source_excerpt || "",
            confidence: task.confidence || "medium",
            ...task
          });
        } else {
          this.log("warn", "validation", "Invalid task found in multi-task result", {
            task,
            taskTitle: task == null ? void 0 : task.task_title
          });
        }
      }
      this.log("info", "validation", "Multi-task validation completed", {
        totalTasks: data.tasks.length,
        validTasks: validTasks.length,
        invalidTasks: data.tasks.length - validTasks.length
      });
      return {
        found: data.found === true && validTasks.length > 0,
        tasks: validTasks,
        confidence: data.confidence || "medium"
      };
    }
    if (data.hasOwnProperty("found")) {
      this.log("info", "validation", "Processing legacy single-task format", {
        found: data.found,
        taskTitle: data.task_title || data.title
      });
      return {
        found: data.found === true,
        task_title: data.task_title || data.title || "",
        task_details: data.task_details || data.details || "",
        due_date: data.due_date || null,
        priority: data.priority || "medium",
        source_excerpt: data.source_excerpt || "",
        ...data
      };
    }
    this.log("warn", "validation", "Parsed data does not match expected format", {
      dataKeys: Object.keys(data),
      hasFound: data.hasOwnProperty("found"),
      hasTasks: data.hasOwnProperty("tasks")
    });
    return null;
  }
  isValidTask(task) {
    if (typeof task !== "object" || !task)
      return false;
    if (!task.task_title || typeof task.task_title !== "string" || task.task_title.trim().length === 0) {
      return false;
    }
    if (task.confidence && !["high", "medium", "low"].includes(task.confidence)) {
      return false;
    }
    if (task.priority && !["high", "medium", "low"].includes(task.priority)) {
      return false;
    }
    if (task.due_date && typeof task.due_date === "string") {
      const dateRegex = /^\d{4}-\d{2}-\d{2}$/;
      if (!dateRegex.test(task.due_date)) {
        return false;
      }
    }
    return true;
  }
  // Create TaskNotesâ€“compatible note in tasksFolder
  async createTaskNote(extraction, sourceFile, correlationId) {
    var _a;
    const safeTitle = this.makeFilenameSafe(extraction.task_title || "task");
    let filename = `${safeTitle}.md`;
    let folder = ((_a = this.settings.tasksFolder) == null ? void 0 : _a.trim()) || "Tasks";
    if (!folder || folder.length === 0) {
      folder = "Tasks";
    }
    folder = folder.replace(/[\\/:*?"<>|]/g, "");
    let path = `${folder}/${filename}`;
    let counter = 1;
    while (this.app.vault.getAbstractFileByPath(path)) {
      path = `${folder}/${safeTitle}-${counter}.md`;
      counter++;
    }
    this.log("info", "task-creation", "Creating task note", {
      sourceFile: sourceFile.path,
      taskTitle: extraction.task_title,
      taskPath: path,
      folder,
      filename: path.split("/").pop()
    }, correlationId);
    const lines = [];
    lines.push("---");
    for (const field of this.settings.frontmatterFields) {
      let value = extraction[field.key] || extraction[field.key.replace("_", "")] || field.defaultValue;
      if (value === "{{date}}") {
        value = new Date().toISOString().split("T")[0];
      }
      if (field.key === "task" && !value && extraction.task_title) {
        value = extraction.task_title;
      }
      if (value) {
        if (field.type === "text" && typeof value === "string" && value.includes(" ")) {
          lines.push(`${field.key}: "${value}"`);
        } else {
          lines.push(`${field.key}: ${value}`);
        }
      }
    }
    lines.push("---");
    lines.push("");
    lines.push(extraction.task_details || "");
    lines.push("");
    if (this.settings.linkBack) {
      const link = `[[${sourceFile.path}]]`;
      lines.push(`Source: ${link}`);
    }
    if (extraction.source_excerpt) {
      lines.push("");
      lines.push("> Justification excerpt:");
      lines.push("> " + extraction.source_excerpt.replace(/\n/g, " "));
    }
    const final = lines.join("\n");
    try {
      await this.app.vault.create(path, final);
      this.log("info", "task-creation", "Task note created successfully", {
        sourceFile: sourceFile.path,
        taskTitle: extraction.task_title,
        taskPath: path,
        contentLength: final.length
      }, correlationId);
      new import_obsidian2.Notice(`Task Extractor: created task "${extraction.task_title}"`);
    } catch (e) {
      console.error("Failed to create task note", e);
      this.log("error", "task-creation", "Failed to create task note", {
        sourceFile: sourceFile.path,
        taskTitle: extraction.task_title,
        taskPath: path,
        error: e instanceof Error ? e.message : String(e),
        stack: e instanceof Error ? e.stack : void 0
      }, correlationId);
      new import_obsidian2.Notice("Task Extractor: failed to create task note \u2014 see console");
    }
  }
  makeFilenameSafe(title) {
    return title.replace(/[\\/:*?"<>|#%{}\\^~\[\]`;'@&=+]/g, "").replace(/\s+/g, "-").slice(0, 120);
  }
  /**
   * Validates frontmatter field name with graceful fallback to "Type"
   * Ensures the field name is valid for YAML and safe to use
   */
  validateFrontmatterField(fieldName) {
    if (!fieldName || typeof fieldName !== "string" || fieldName.trim().length === 0) {
      console.warn('TaskExtractor: Empty frontmatter field name, falling back to "Type"');
      return "Type";
    }
    const trimmed = fieldName.trim();
    const yamlKeyPattern = /^[a-zA-Z_][a-zA-Z0-9_.-]*$/;
    if (!yamlKeyPattern.test(trimmed)) {
      console.warn(`TaskExtractor: Invalid frontmatter field name "${trimmed}", falling back to "Type"`);
      return "Type";
    }
    if (trimmed.includes("..") || trimmed.startsWith(".") || trimmed.endsWith(".")) {
      console.warn(`TaskExtractor: Problematic frontmatter field name "${trimmed}", falling back to "Type"`);
      return "Type";
    }
    return trimmed;
  }
  // Enhanced cleanup method with processing queue management
  cleanup() {
    this.fileChangeDebouncer.forEach((timeout) => clearTimeout(timeout));
    this.fileChangeDebouncer.clear();
    this.processingQueue.forEach((status) => {
      if (status.timeout) {
        clearTimeout(status.timeout);
      }
    });
    this.processingQueue.clear();
    this.processingFiles.clear();
  }
  // Methods for backward compatibility
  getProcessingFiles() {
    return this.processingFiles;
  }
};

// src/settings.ts
var import_obsidian3 = require("obsidian");
var ExtractorSettingTab = class extends import_obsidian3.PluginSettingTab {
  constructor(app, plugin, settings, llmProvider) {
    super(app, plugin);
    this.plugin = plugin;
    this.settings = settings;
    this.llmProvider = llmProvider;
    this.saveTimeout = null;
  }
  // Debounced save to reduce save frequency
  debouncedSave() {
    if (this.saveTimeout) {
      clearTimeout(this.saveTimeout);
    }
    this.saveTimeout = setTimeout(async () => {
      await this.plugin.saveSettings();
      this.saveTimeout = null;
    }, 500);
  }
  // Clean up timeout on hide
  hide() {
    if (this.saveTimeout) {
      clearTimeout(this.saveTimeout);
      this.saveTimeout = null;
    }
    super.hide();
  }
  /**
   * Validates frontmatter field name according to YAML key format
   * Returns a valid field name or defaults to "Type"
   */
  validateFrontmatterField(fieldName) {
    if (!fieldName || fieldName.length === 0) {
      return "Type";
    }
    const yamlKeyPattern = /^[a-zA-Z_][a-zA-Z0-9_.-]*$/;
    if (!yamlKeyPattern.test(fieldName)) {
      return "Type";
    }
    if (fieldName.includes("..") || fieldName.startsWith(".") || fieldName.endsWith(".")) {
      return "Type";
    }
    return fieldName;
  }
  /**
   * Shows validation feedback to the user
   */
  showValidationFeedback(inputEl, message) {
    inputEl.style.borderColor = "#ff6b6b";
    inputEl.style.backgroundColor = "rgba(255, 107, 107, 0.1)";
    inputEl.title = message;
    setTimeout(() => {
      inputEl.style.borderColor = "";
      inputEl.style.backgroundColor = "";
      inputEl.title = "";
    }, 3e3);
  }
  /**
   * Validates and clamps numeric values with enhanced error handling
   */
  validateNumericInput(value, min, max, defaultValue) {
    if (isNaN(value)) {
      return {
        value: defaultValue,
        isValid: false,
        message: `Invalid number. Using default value ${defaultValue}.`
      };
    }
    if (value < min) {
      return {
        value: min,
        isValid: false,
        message: `Value too low. Minimum is ${min}.`
      };
    }
    if (value > max) {
      return {
        value: max,
        isValid: false,
        message: `Value too high. Maximum is ${max}.`
      };
    }
    return { value, isValid: true };
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Task Extractor Settings" });
    this.addProviderSection(containerEl);
    this.addLocalLLMSection(containerEl);
    this.addProcessingSection(containerEl);
    this.addFrontmatterSection(containerEl);
    this.addDebugSection(containerEl);
    this.addAdvancedSection(containerEl);
  }
  addProviderSection(containerEl) {
    containerEl.createEl("h3", { text: "LLM Provider Configuration" });
    const statusEl = containerEl.createEl("div", { cls: "task-extractor-status" });
    this.updateServiceStatus(statusEl);
    new import_obsidian3.Setting(containerEl).setName("Provider").setDesc("Choose LLM provider. Local providers (Ollama/LM Studio) require the service to be running.").addDropdown((cb) => cb.addOption("openai", "OpenAI").addOption("anthropic", "Anthropic").addOption("ollama", "Ollama (Local)").addOption("lmstudio", "LM Studio (Local)").setValue(this.settings.provider).onChange((v) => {
      this.settings.provider = v;
      this.debouncedSave();
      this.llmProvider.getApiKeyMissingNotified().clear();
      this.updateServiceStatus(statusEl);
      this.display();
    }));
    if (["openai", "anthropic"].includes(this.settings.provider)) {
      new import_obsidian3.Setting(containerEl).setName("API Key").setDesc("Your API key for the selected provider. Models will be loaded automatically once entered.").addText((text) => text.setPlaceholder("sk-... or claude-...").setValue(this.settings.apiKey).onChange((v) => {
        this.settings.apiKey = v.trim();
        this.debouncedSave();
        const oldCacheKeys = Array.from(this.llmProvider.getCloudModelCache().keys()).filter((key) => key.startsWith(this.settings.provider));
        oldCacheKeys.forEach((key) => this.llmProvider.getCloudModelCache().delete(key));
        this.llmProvider.getApiKeyMissingNotified().clear();
        this.display();
      }));
    }
    this.addModelSetting(containerEl);
  }
  async addModelSetting(containerEl) {
    const modelContainer = containerEl.createDiv();
    const provider = this.settings.provider;
    const service = this.llmProvider.getServiceCache().get(provider);
    if (["ollama", "lmstudio"].includes(provider) && (service == null ? void 0 : service.available) && service.models.length > 0) {
      new import_obsidian3.Setting(modelContainer).setName("Model").setDesc(`Select from ${service.models.length} available ${provider} models.`).addDropdown((cb) => {
        service.models.forEach((model) => cb.addOption(model, model));
        cb.setValue(this.settings.model || service.models[0]).onChange((v) => {
          this.settings.model = v;
          this.debouncedSave();
        });
      });
    } else if (["openai", "anthropic"].includes(provider) && this.settings.apiKey) {
      const loadingSetting = new import_obsidian3.Setting(modelContainer).setName("Model").setDesc("Loading available models...");
      try {
        const availableModels = await this.llmProvider.fetchCloudModels(provider);
        modelContainer.empty();
        new import_obsidian3.Setting(modelContainer).setName("Model").setDesc(`Select from ${availableModels.length} available ${provider} models.`).addDropdown((cb) => {
          availableModels.forEach((model) => cb.addOption(model, model));
          const currentModel = this.settings.model;
          const defaultModel = availableModels.includes(currentModel) ? currentModel : availableModels[0];
          cb.setValue(defaultModel).onChange((v) => {
            this.settings.model = v;
            this.debouncedSave();
          });
        });
        new import_obsidian3.Setting(modelContainer).setName("Refresh Models").setDesc("Reload the list of available models from the API.").addButton((button) => button.setButtonText("Refresh").onClick(async () => {
          this.llmProvider.getCloudModelCache().clear();
          this.display();
        }));
      } catch (error) {
        modelContainer.empty();
        this.addFallbackModelSetting(modelContainer, provider);
      }
    } else {
      this.addFallbackModelSetting(modelContainer, provider);
    }
  }
  addFallbackModelSetting(container, provider) {
    const defaultModels = {
      openai: "gpt-4o-mini",
      anthropic: "claude-3-haiku-20240307",
      ollama: "llama3.2",
      lmstudio: "local-model"
    };
    const description = ["ollama", "lmstudio"].includes(provider) ? `Enter model name. Service not detected or no models available.` : `Enter model name manually.`;
    new import_obsidian3.Setting(container).setName("Model").setDesc(description).addText((text) => text.setPlaceholder(defaultModels[provider] || "").setValue(this.settings.model).onChange((v) => {
      this.settings.model = v.trim();
      this.debouncedSave();
    }));
  }
  addLocalLLMSection(containerEl) {
    containerEl.createEl("h3", { text: "Local LLM Configuration" });
    if (this.settings.provider === "ollama") {
      new import_obsidian3.Setting(containerEl).setName("Ollama URL").setDesc("URL for your Ollama instance.").addText((text) => text.setValue(this.settings.ollamaUrl).onChange((v) => {
        this.settings.ollamaUrl = v.trim();
        this.debouncedSave();
      }));
    }
    if (this.settings.provider === "lmstudio") {
      new import_obsidian3.Setting(containerEl).setName("LM Studio URL").setDesc("URL for your LM Studio instance.").addText((text) => text.setValue(this.settings.lmstudioUrl).onChange((v) => {
        this.settings.lmstudioUrl = v.trim();
        this.debouncedSave();
      }));
    }
    this.addSliderWithInput(
      containerEl,
      "Model Refresh Interval",
      "How often to check for available models (minutes).",
      this.settings.localModelRefreshInterval,
      1,
      60,
      1,
      (v) => {
        this.settings.localModelRefreshInterval = v;
        this.debouncedSave();
      }
    );
  }
  addProcessingSection(containerEl) {
    containerEl.createEl("h3", { text: "Processing Settings" });
    new import_obsidian3.Setting(containerEl).setName("Owner name").setDesc("Exact name the LLM should look for when deciding tasks.").addText((text) => text.setPlaceholder("Bryan Kolb").setValue(this.settings.ownerName).onChange((v) => {
      this.settings.ownerName = v.trim();
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Tasks folder").setDesc("Folder where generated task notes will be created.").addText((text) => text.setValue(this.settings.tasksFolder).onChange((v) => {
      this.settings.tasksFolder = v.trim();
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Trigger note types").setDesc("Comma-separated list of note types to process (from frontmatter Type field).").addText((text) => text.setValue(this.settings.triggerTypes.join(", ")).onChange((v) => {
      this.settings.triggerTypes = v.split(",").map((s) => s.trim()).filter((s) => s.length > 0);
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Frontmatter field for filtering").setDesc('The frontmatter field name to use for filtering notes (e.g., "Type", "Category", "NoteType").').addText((text) => text.setPlaceholder("Type").setValue(this.settings.triggerFrontmatterField).onChange((v) => {
      const validatedField = this.validateFrontmatterField(v.trim());
      this.settings.triggerFrontmatterField = validatedField;
      this.debouncedSave();
      if (validatedField !== v.trim()) {
        text.setValue(validatedField);
        this.showValidationFeedback(text.inputEl, 'Invalid field name. Using default "Type".');
      }
    }));
    new import_obsidian3.Setting(containerEl).setName("Process edits as well as new files").setDesc("If enabled, modifications to matching notes will be processed too.").addToggle((toggle) => toggle.setValue(this.settings.processOnUpdate).onChange((v) => {
      this.settings.processOnUpdate = v;
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Link back to source").setDesc("Insert a link back to the source note in generated task notes.").addToggle((toggle) => toggle.setValue(this.settings.linkBack).onChange((v) => {
      this.settings.linkBack = v;
      this.debouncedSave();
    }));
    new import_obsidian3.Setting(containerEl).setName("Processed marker key").setDesc("Frontmatter key to mark processed notes.").addText((text) => text.setValue(this.settings.processedFrontmatterKey).onChange((v) => {
      this.settings.processedFrontmatterKey = v.trim();
      this.debouncedSave();
    }));
  }
  addFrontmatterSection(containerEl) {
    containerEl.createEl("h3", { text: "Task Note Frontmatter" });
    new import_obsidian3.Setting(containerEl).setName("Add Field").setDesc("Add a new frontmatter field").addButton((button) => button.setButtonText("Add Field").onClick(() => {
      this.settings.frontmatterFields.push({
        key: "new_field",
        defaultValue: "",
        type: "text",
        required: false
      });
      this.debouncedSave();
      this.display();
    }));
    this.settings.frontmatterFields.forEach((field, index) => {
      const fieldContainer = containerEl.createDiv({ cls: "task-extractor-field" });
      new import_obsidian3.Setting(fieldContainer).setName(`Field ${index + 1}: ${field.key}`).setDesc(`Type: ${field.type}, Required: ${field.required ? "Yes" : "No"}`).addButton((button) => button.setButtonText("Remove").onClick(() => {
        this.settings.frontmatterFields.splice(index, 1);
        this.debouncedSave();
        this.display();
      }));
    });
    new import_obsidian3.Setting(containerEl).setName("Custom Prompt").setDesc("Override the default task extraction prompt. Leave empty to use default.").addTextArea((text) => text.setPlaceholder("Enter custom prompt...").setValue(this.settings.customPrompt).onChange((v) => {
      this.settings.customPrompt = v;
      this.debouncedSave();
    }));
  }
  addDebugSection(containerEl) {
    containerEl.createEl("h3", { text: "Debug Settings" });
    new import_obsidian3.Setting(containerEl).setName("Debug Mode").setDesc("Enable debug logging to monitor plugin activities. Logs are stored in memory only and cleared when Obsidian restarts.").addToggle((toggle) => toggle.setValue(this.settings.debugMode).onChange((v) => {
      this.settings.debugMode = v;
      this.debouncedSave();
      this.display();
    }));
    if (this.settings.debugMode) {
      this.addSliderWithInput(
        containerEl,
        "Max Debug Entries",
        "Maximum number of debug log entries to keep in memory. Older entries are automatically removed.",
        this.settings.debugMaxEntries,
        100,
        1e4,
        100,
        (v) => {
          this.settings.debugMaxEntries = v;
          this.debouncedSave();
        }
      );
    }
  }
  addAdvancedSection(containerEl) {
    containerEl.createEl("h3", { text: "Advanced Settings" });
    this.addSliderWithInput(
      containerEl,
      "Max Tokens",
      "Maximum tokens to generate.",
      this.settings.maxTokens,
      100,
      2e3,
      50,
      (v) => {
        this.settings.maxTokens = v;
        this.debouncedSave();
      }
    );
    this.addSliderWithInput(
      containerEl,
      "Temperature",
      "Creativity level (0 = deterministic, 1 = creative).",
      this.settings.temperature,
      0,
      1,
      0.1,
      (v) => {
        this.settings.temperature = v;
        this.debouncedSave();
      }
    );
    this.addSliderWithInput(
      containerEl,
      "Timeout (seconds)",
      "Request timeout for LLM calls.",
      this.settings.timeout,
      10,
      120,
      5,
      (v) => {
        this.settings.timeout = v;
        this.debouncedSave();
      }
    );
    this.addSliderWithInput(
      containerEl,
      "Retry Attempts",
      "Number of retry attempts for failed requests.",
      this.settings.retries,
      1,
      5,
      1,
      (v) => {
        this.settings.retries = v;
        this.debouncedSave();
      }
    );
  }
  /**
   * Helper method to create an enhanced slider with input field
   * Provides bidirectional synchronization between slider and number input
   */
  addSliderWithInput(containerEl, name, desc, value, min, max, step, onChange) {
    const setting = new import_obsidian3.Setting(containerEl).setName(name).setDesc(desc);
    const controlContainer = setting.controlEl.createDiv({ cls: "task-extractor-slider-input-container" });
    const sliderEl = controlContainer.createEl("input", {
      type: "range",
      cls: "task-extractor-slider"
    });
    sliderEl.min = min.toString();
    sliderEl.max = max.toString();
    sliderEl.step = step.toString();
    sliderEl.value = value.toString();
    const inputEl = controlContainer.createEl("input", {
      type: "number",
      cls: "task-extractor-number-input"
    });
    inputEl.min = min.toString();
    inputEl.max = max.toString();
    inputEl.step = step.toString();
    inputEl.value = value.toString();
    sliderEl.addEventListener("input", () => {
      const newValue = parseFloat(sliderEl.value);
      const validation = this.validateNumericInput(newValue, min, max, value);
      inputEl.value = validation.value.toString();
      onChange(validation.value);
    });
    inputEl.addEventListener("input", () => {
      const newValue = parseFloat(inputEl.value);
      const validation = this.validateNumericInput(newValue, min, max, value);
      if (!validation.isValid) {
        inputEl.value = validation.value.toString();
        this.showValidationFeedback(inputEl, validation.message || "Invalid value");
      }
      sliderEl.value = validation.value.toString();
      onChange(validation.value);
    });
    inputEl.addEventListener("blur", () => {
      const newValue = parseFloat(inputEl.value);
      const validation = this.validateNumericInput(newValue, min, max, value);
      inputEl.value = validation.value.toString();
      sliderEl.value = validation.value.toString();
      if (!validation.isValid) {
        this.showValidationFeedback(inputEl, validation.message || "Value corrected");
      }
    });
    controlContainer.style.display = "flex";
    controlContainer.style.alignItems = "center";
    controlContainer.style.gap = "12px";
    controlContainer.style.width = "100%";
    sliderEl.style.flex = "1";
    sliderEl.style.minWidth = "120px";
    sliderEl.style.height = "20px";
    inputEl.style.width = "80px";
    inputEl.style.textAlign = "center";
    inputEl.style.padding = "4px 8px";
    inputEl.style.border = "1px solid var(--background-modifier-border)";
    inputEl.style.borderRadius = "4px";
    inputEl.style.backgroundColor = "var(--background-primary)";
    inputEl.style.color = "var(--text-normal)";
    inputEl.style.fontSize = "13px";
  }
  updateServiceStatus(statusEl) {
    statusEl.empty();
    const provider = this.settings.provider;
    const service = this.llmProvider.getServiceCache().get(provider);
    if (["ollama", "lmstudio"].includes(provider)) {
      if (service == null ? void 0 : service.available) {
        statusEl.createEl("div", {
          text: `\u2705 ${provider} connected (${service.models.length} models)`,
          cls: "task-extractor-status-success"
        });
      } else {
        statusEl.createEl("div", {
          text: `\u274C ${provider} not available`,
          cls: "task-extractor-status-error"
        });
      }
    } else {
      if (this.settings.apiKey) {
        statusEl.createEl("div", {
          text: `\u2705 ${provider} API key configured`,
          cls: "task-extractor-status-success"
        });
      } else {
        statusEl.createEl("div", {
          text: `\u274C ${provider} API key required`,
          cls: "task-extractor-status-error"
        });
      }
    }
  }
};

// main.ts
var TaskExtractorPlugin = class extends import_obsidian4.Plugin {
  constructor() {
    super(...arguments);
    this.processingFiles = /* @__PURE__ */ new Set();
    this.serviceCache = /* @__PURE__ */ new Map();
    this.serviceCheckInterval = null;
    this.cloudModelCache = /* @__PURE__ */ new Map();
    this.apiKeyMissingNotified = /* @__PURE__ */ new Set();
    this.fileChangeDebouncer = /* @__PURE__ */ new Map();
  }
  async onload() {
    console.log("Loading Task Extractor plugin...");
    await this.loadSettings();
    this.llmProvider = new LLMProviderManager(this.settings);
    this.taskProcessor = new TaskProcessor(this.app, this.settings, this.llmProvider);
    this.serviceCache = this.llmProvider.getServiceCache();
    this.cloudModelCache = this.llmProvider.getCloudModelCache();
    this.apiKeyMissingNotified = this.llmProvider.getApiKeyMissingNotified();
    this.processingFiles = this.taskProcessor.getProcessingFiles();
    this.addSettingTab(new ExtractorSettingTab(this.app, this, this.settings, this.llmProvider));
    this.registerEvent(
      this.app.vault.on("create", (file) => {
        if (file instanceof import_obsidian4.TFile) {
          this.debounceFileChange(file);
        }
      })
    );
    if (this.settings.processOnUpdate) {
      this.registerEvent(
        this.app.vault.on("modify", (file) => {
          if (file instanceof import_obsidian4.TFile) {
            this.debounceFileChange(file);
          }
        })
      );
    }
    await this.initializeServices();
    this.scanExistingFiles();
  }
  onunload() {
    console.log("Unloading Task Extractor plugin...");
    if (this.serviceCheckInterval) {
      clearInterval(this.serviceCheckInterval);
      this.serviceCheckInterval = null;
    }
    this.fileChangeDebouncer.forEach((timeout) => clearTimeout(timeout));
    this.fileChangeDebouncer.clear();
    this.cloudModelCache.clear();
    this.apiKeyMissingNotified.clear();
  }
  async loadSettings() {
    const rawSettings = await this.loadData();
    this.settings = validateSettings(Object.assign({}, DEFAULT_SETTINGS, rawSettings));
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
  // Debounce file changes to prevent rapid processing
  debounceFileChange(file) {
    const existing = this.fileChangeDebouncer.get(file.path);
    if (existing) {
      clearTimeout(existing);
    }
    this.fileChangeDebouncer.set(file.path, setTimeout(() => {
      this.onFileChanged(file);
      this.fileChangeDebouncer.delete(file.path);
    }, 2e3));
  }
  // Delegate to task processor
  async onFileChanged(file) {
    return this.taskProcessor.onFileChanged(file);
  }
  async scanExistingFiles() {
    return this.taskProcessor.scanExistingFiles();
  }
  // Service Detection and Management - delegate to LLM provider
  async initializeServices() {
  }
  async detectServices() {
    return this.llmProvider.detectServices();
  }
  getAvailableServices() {
    return this.llmProvider.getAvailableServices();
  }
  // LLM calls - delegate to provider
  async callLLM(systemPrompt, userPrompt) {
    return this.llmProvider.callLLM(systemPrompt, userPrompt);
  }
  async fetchCloudModels(provider) {
    return this.llmProvider.fetchCloudModels(provider);
  }
  getDefaultModels(provider) {
    return this.llmProvider.getDefaultModels(provider);
  }
};
