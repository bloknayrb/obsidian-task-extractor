/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => TaskExtractorPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian = require("obsidian");
var DEFAULT_FRONTMATTER_FIELDS = [
  { key: "task", defaultValue: "", type: "text", required: true },
  { key: "status", defaultValue: "todo", type: "select", options: ["todo", "doing", "done", "cancelled"], required: true },
  { key: "priority", defaultValue: "medium", type: "select", options: ["low", "medium", "high", "urgent"], required: true },
  { key: "due", defaultValue: "", type: "date", required: false },
  { key: "project", defaultValue: "", type: "text", required: false },
  { key: "client", defaultValue: "", type: "text", required: false },
  { key: "created", defaultValue: "{{date}}", type: "date", required: false },
  { key: "tags", defaultValue: "task", type: "text", required: false }
];
var DEFAULT_SETTINGS = {
  provider: "openai",
  apiKey: "",
  model: "gpt-4o-mini",
  // Local LLM settings
  ollamaUrl: "http://localhost:11434",
  lmstudioUrl: "http://localhost:1234",
  localModelRefreshInterval: 5,
  // Processing settings
  tasksFolder: "Tasks",
  linkBack: true,
  processedFrontmatterKey: "taskExtractor.processed",
  ownerName: "Bryan Kolb",
  processOnUpdate: false,
  triggerTypes: ["email", "meetingnote", "meeting note", "meeting notes"],
  // Customizable frontmatter
  frontmatterFields: DEFAULT_FRONTMATTER_FIELDS,
  customPrompt: "",
  // Advanced settings
  maxTokens: 800,
  temperature: 0,
  timeout: 30,
  retries: 3
};
var TaskExtractorPlugin = class extends import_obsidian.Plugin {
  constructor() {
    super(...arguments);
    this.processingFiles = /* @__PURE__ */ new Set();
    this.serviceCache = /* @__PURE__ */ new Map();
    this.serviceCheckInterval = null;
  }
  async onload() {
    console.log("Loading Task Extractor plugin...");
    await this.loadSettings();
    this.addSettingTab(new ExtractorSettingTab(this.app, this));
    this.registerEvent(
      this.app.vault.on("create", (file) => {
        if (file instanceof import_obsidian.TFile) {
          this.onFileChanged(file);
        }
      })
    );
    if (this.settings.processOnUpdate) {
      this.registerEvent(
        this.app.vault.on("modify", (file) => {
          if (file instanceof import_obsidian.TFile) {
            this.onFileChanged(file);
          }
        })
      );
    }
    await this.initializeServices();
    this.setupServiceMonitoring();
    this.scanExistingFiles();
  }
  onunload() {
    console.log("Unloading Task Extractor plugin...");
    if (this.serviceCheckInterval) {
      clearInterval(this.serviceCheckInterval);
      this.serviceCheckInterval = null;
    }
  }
  async loadSettings() {
    this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
  }
  async saveSettings() {
    await this.saveData(this.settings);
  }
  // When a file is created or modified
  async onFileChanged(file) {
    try {
      if (file.extension !== "md")
        return;
      if (this.processingFiles.has(file.path))
        return;
      this.processingFiles.add(file.path);
      const cache = this.app.metadataCache.getFileCache(file);
      const front = cache == null ? void 0 : cache.frontmatter;
      if (!front)
        return;
      const processedValue = this.getFrontmatterValue(front, this.settings.processedFrontmatterKey);
      if (processedValue === true || processedValue === "true") {
        this.processingFiles.delete(file.path);
        return;
      }
      const typeRaw = this.getFrontmatterValue(front, "Type") || "";
      const type = ("" + typeRaw).toLowerCase();
      const accepted = this.settings.triggerTypes.map((t) => t.toLowerCase());
      if (!accepted.includes(type)) {
        this.processingFiles.delete(file.path);
        return;
      }
      const content = await this.app.vault.read(file);
      const extraction = await this.extractTaskFromContent(content, file.path);
      if (extraction && extraction.found) {
        await this.createTaskNote(extraction, file);
      }
      await this.markFileProcessed(file);
      this.processingFiles.delete(file.path);
    } catch (err) {
      console.error("TaskExtractor error", err);
      new import_obsidian.Notice("Task Extractor: error processing file \u2014 see console");
      try {
        this.processingFiles.delete(file.path);
      } catch (e) {
      }
    }
  }
  // scan vault once on load for unprocessed matching notes
  async scanExistingFiles() {
    const files = this.app.vault.getMarkdownFiles();
    for (const f of files) {
      const cache = this.app.metadataCache.getFileCache(f);
      const front = cache == null ? void 0 : cache.frontmatter;
      if (!front)
        continue;
      const typeRaw = this.getFrontmatterValue(front, "Type") || "";
      const type = ("" + typeRaw).toLowerCase();
      const accepted = this.settings.triggerTypes.map((t) => t.toLowerCase());
      const processedValue = this.getFrontmatterValue(front, this.settings.processedFrontmatterKey);
      if (accepted.includes(type) && !(processedValue === true || processedValue === "true")) {
        await this.onFileChanged(f);
      }
    }
  }
  getFrontmatterValue(front, key) {
    if (!front)
      return void 0;
    if (key.includes(".")) {
      const parts = key.split(".");
      let cur = front;
      for (const p of parts) {
        if (!cur)
          return void 0;
        cur = cur[p];
      }
      return cur;
    }
    return front[key];
  }
  async markFileProcessed(file) {
    if (!this.settings.processedFrontmatterKey)
      return;
    try {
      const content = await this.app.vault.read(file);
      const fmMatch = content.match(/^---\n([\s\S]*?)\n---/);
      let newContent = content;
      if (fmMatch) {
        const fm = fmMatch[1];
        const lines = fm.split("\n");
        const processedKey = this.settings.processedFrontmatterKey;
        if (!new RegExp("^" + processedKey.replace(".", ".") + ":", "m").test(fm)) {
          lines.push(`${processedKey}: true`);
          const updatedFm = lines.join("\n");
          newContent = content.replace(fmMatch[0], `---
${updatedFm}
---`);
          await this.app.vault.modify(file, newContent);
        }
      } else {
        const processedKey = this.settings.processedFrontmatterKey;
        newContent = `---
${processedKey}: true
---

` + content;
        await this.app.vault.modify(file, newContent);
      }
    } catch (e) {
      console.warn("Failed to mark file processed", e);
    }
  }
  // Service Detection and Management
  async initializeServices() {
    await this.detectServices();
  }
  setupServiceMonitoring() {
    if (this.serviceCheckInterval) {
      clearInterval(this.serviceCheckInterval);
    }
    const intervalMs = this.settings.localModelRefreshInterval * 60 * 1e3;
    this.serviceCheckInterval = setInterval(async () => {
      await this.detectServices();
    }, intervalMs);
  }
  async detectServices() {
    var _a, _b;
    const services = /* @__PURE__ */ new Map();
    const now = Date.now();
    const ollamaService = {
      name: "ollama",
      url: this.settings.ollamaUrl,
      available: false,
      models: [],
      lastChecked: now
    };
    try {
      const ollamaResponse = await fetch(`${this.settings.ollamaUrl}/api/tags`, {
        signal: this.createTimeoutSignal(5e3)
      });
      if (ollamaResponse.ok) {
        const data = await ollamaResponse.json();
        ollamaService.available = true;
        ollamaService.models = ((_a = data.models) == null ? void 0 : _a.map((m) => m.name)) || [];
      }
    } catch (error) {
      console.log("Ollama not available:", error.message);
    }
    services.set("ollama", ollamaService);
    const lmstudioService = {
      name: "lmstudio",
      url: this.settings.lmstudioUrl,
      available: false,
      models: [],
      lastChecked: now
    };
    try {
      const lmstudioResponse = await fetch(`${this.settings.lmstudioUrl}/v1/models`, {
        signal: this.createTimeoutSignal(5e3)
      });
      if (lmstudioResponse.ok) {
        const data = await lmstudioResponse.json();
        lmstudioService.available = true;
        lmstudioService.models = ((_b = data.data) == null ? void 0 : _b.map((m) => m.id)) || [];
      }
    } catch (error) {
      console.log("LM Studio not available:", error.message);
    }
    services.set("lmstudio", lmstudioService);
    this.serviceCache = services;
    return services;
  }
  getAvailableServices() {
    return Array.from(this.serviceCache.values()).filter((s) => s.available);
  }
  // Compose prompt, call LLM, and parse response
  async extractTaskFromContent(content, sourcePath) {
    const basePrompt = this.settings.customPrompt || `You are a task extraction assistant. You will be given the full text of an email or meeting note. Determine if there is an explicit or implied actionable task for ${this.settings.ownerName} (exact name). If there is a task, output a single JSON object and nothing else. If there is no task, output {"found": false}.`;
    const fieldDescriptions = this.settings.frontmatterFields.filter((f) => f.required || f.key === "task_title" || f.key === "task_details").map((f) => {
      var _a;
      if (f.key === "task" || f.key === "task_title")
        return "- task_title: short (6-12 words) actionable title";
      if (f.key === "task_details")
        return "- task_details: 1-3 sentences describing what to do and any context";
      if (f.key === "due")
        return "- due_date: ISO date YYYY-MM-DD if explicitly present in the text, otherwise null";
      if (f.key === "priority")
        return `- priority: ${((_a = f.options) == null ? void 0 : _a.join("|")) || "high|medium|low"} (choose best match)`;
      if (f.key === "project")
        return "- project: project name if mentioned, otherwise null";
      if (f.key === "client")
        return "- client: client name if mentioned, otherwise null";
      return `- ${f.key}: ${f.defaultValue || "appropriate value based on context"}`;
    });
    const system = `${basePrompt} The JSON, when found, must include these keys:
${fieldDescriptions.join("\n")}
- source_excerpt: a short quoted excerpt from the note that justifies the decision (max 3 lines)
Return valid JSON only.`;
    const user = `SOURCE_PATH: ${sourcePath}
---BEGIN NOTE---
${content}
---END NOTE---`;
    try {
      const raw = await this.callLLM(system, user);
      const parsed = this.safeParseJSON(raw);
      if (!parsed)
        return { found: false };
      if (!parsed.found)
        return { found: false };
      return {
        found: true,
        task_title: parsed.task_title || parsed.title || "Unspecified task",
        task_details: parsed.task_details || parsed.details || "",
        due_date: parsed.due_date || null,
        priority: parsed.priority || "medium",
        source_excerpt: parsed.source_excerpt || ""
      };
    } catch (e) {
      console.error("extractTaskFromContent error", e);
      return { found: false };
    }
  }
  safeParseJSON(text) {
    if (!text)
      return null;
    try {
      return JSON.parse(text);
    } catch (e) {
    }
    const m = text.match(/\{[\s\S]*\}/);
    if (m) {
      try {
        return JSON.parse(m[0]);
      } catch (e) {
      }
    }
    const fixed = text.replace(/'/g, '"');
    try {
      return JSON.parse(fixed);
    } catch (e) {
    }
    return null;
  }
  // Create TaskNotesâ€“compatible note in tasksFolder
  async createTaskNote(extraction, sourceFile) {
    const safeTitle = this.makeFilenameSafe(extraction.task_title || "task");
    let filename = `${safeTitle}.md`;
    let folder = this.settings.tasksFolder.trim() || "Tasks";
    let path = `${folder}/${filename}`;
    let counter = 1;
    while (this.app.vault.getAbstractFileByPath(path)) {
      path = `${folder}/${safeTitle}-${counter}.md`;
      counter++;
    }
    const lines = [];
    lines.push("---");
    for (const field of this.settings.frontmatterFields) {
      let value = extraction[field.key] || extraction[field.key.replace("_", "")] || field.defaultValue;
      if (value === "{{date}}") {
        value = new Date().toISOString().split("T")[0];
      }
      if (field.key === "task" && !value && extraction.task_title) {
        value = extraction.task_title;
      }
      if (value) {
        if (field.type === "text" && typeof value === "string" && value.includes(" ")) {
          lines.push(`${field.key}: "${value}"`);
        } else {
          lines.push(`${field.key}: ${value}`);
        }
      }
    }
    lines.push("---");
    lines.push("");
    lines.push(extraction.task_details || "");
    lines.push("");
    if (this.settings.linkBack) {
      const link = `[[${sourceFile.path}]]`;
      lines.push(`Source: ${link}`);
    }
    if (extraction.source_excerpt) {
      lines.push("");
      lines.push("> Justification excerpt:");
      lines.push("> " + extraction.source_excerpt.replace(/\n/g, " "));
    }
    const final = lines.join("\n");
    try {
      await this.app.vault.create(path, final);
      new import_obsidian.Notice(`Task Extractor: created task "${extraction.task_title}"`);
    } catch (e) {
      console.error("Failed to create task note", e);
      new import_obsidian.Notice("Task Extractor: failed to create task note \u2014 see console");
    }
  }
  makeFilenameSafe(title) {
    return title.replace(/[\\/:*?"<>|#%{}\\^~\[\]`;'@&=+]/g, "").replace(/\s+/g, "-").slice(0, 120);
  }
  // Provider-agnostic LLM call with fallback support
  async callLLM(systemPrompt, userPrompt) {
    const provider = this.settings.provider;
    if (["openai", "anthropic"].includes(provider) && !this.settings.apiKey) {
      new import_obsidian.Notice("Task Extractor: API key not configured in plugin settings");
      return null;
    }
    for (let attempt = 0; attempt < this.settings.retries; attempt++) {
      try {
        let result = null;
        switch (provider) {
          case "openai":
            result = await this.callOpenAI(systemPrompt, userPrompt);
            break;
          case "anthropic":
            result = await this.callAnthropic(systemPrompt, userPrompt);
            break;
          case "ollama":
            result = await this.callOllama(systemPrompt, userPrompt);
            break;
          case "lmstudio":
            result = await this.callLMStudio(systemPrompt, userPrompt);
            break;
          default:
            throw new Error(`Unsupported provider: ${provider}`);
        }
        if (result)
          return result;
      } catch (error) {
        console.warn(`Attempt ${attempt + 1} failed for ${provider}:`, error.message);
        if (attempt === this.settings.retries - 1) {
          if (["ollama", "lmstudio"].includes(provider)) {
            return await this.tryLocalFallback(systemPrompt, userPrompt);
          }
        } else {
          await this.delay(Math.pow(2, attempt) * 1e3);
        }
      }
    }
    return null;
  }
  async tryLocalFallback(systemPrompt, userPrompt) {
    const availableServices = this.getAvailableServices();
    for (const service of availableServices) {
      if (service.name === this.settings.provider)
        continue;
      try {
        console.log(`Trying fallback to ${service.name}`);
        if (service.name === "ollama") {
          return await this.callOllama(systemPrompt, userPrompt);
        } else if (service.name === "lmstudio") {
          return await this.callLMStudio(systemPrompt, userPrompt);
        }
      } catch (error) {
        console.warn(`Fallback to ${service.name} failed:`, error.message);
      }
    }
    new import_obsidian.Notice("Task Extractor: All LLM services failed. Check your configuration.");
    return null;
  }
  delay(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
  createTimeoutSignal(ms) {
    const controller = new AbortController();
    setTimeout(() => controller.abort(), ms);
    return controller.signal;
  }
  async callOpenAI(systemPrompt, userPrompt) {
    var _a, _b, _c;
    const endpoint = "https://api.openai.com/v1/chat/completions";
    const body = {
      model: this.settings.model || "gpt-4o-mini",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt }
      ],
      temperature: this.settings.temperature,
      max_tokens: this.settings.maxTokens
    };
    try {
      const resp = await fetch(endpoint, {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${this.settings.apiKey}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify(body),
        signal: this.createTimeoutSignal(this.settings.timeout * 1e3)
      });
      if (!resp.ok) {
        const text = await resp.text();
        console.error("OpenAI error", resp.status, text);
        throw new Error(`OpenAI API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      return ((_c = (_b = (_a = json == null ? void 0 : json.choices) == null ? void 0 : _a[0]) == null ? void 0 : _b.message) == null ? void 0 : _c.content) || null;
    } catch (e) {
      console.error("callOpenAI error", e);
      throw e;
    }
  }
  async callAnthropic(systemPrompt, userPrompt) {
    var _a, _b;
    const endpoint = "https://api.anthropic.com/v1/messages";
    try {
      const resp = await fetch(endpoint, {
        method: "POST",
        headers: {
          "x-api-key": this.settings.apiKey,
          "Content-Type": "application/json",
          "anthropic-version": "2023-06-01"
        },
        body: JSON.stringify({
          model: this.settings.model || "claude-3-sonnet-20240229",
          max_tokens: this.settings.maxTokens,
          temperature: this.settings.temperature,
          system: systemPrompt,
          messages: [{
            role: "user",
            content: userPrompt
          }]
        }),
        signal: this.createTimeoutSignal(this.settings.timeout * 1e3)
      });
      if (!resp.ok) {
        const text = await resp.text();
        console.error("Anthropic error", resp.status, text);
        throw new Error(`Anthropic API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      return ((_b = (_a = json == null ? void 0 : json.content) == null ? void 0 : _a[0]) == null ? void 0 : _b.text) || null;
    } catch (e) {
      console.error("callAnthropic error", e);
      throw e;
    }
  }
  async callOllama(systemPrompt, userPrompt) {
    var _a;
    const service = this.serviceCache.get("ollama");
    if (!(service == null ? void 0 : service.available) || !service.models.length) {
      throw new Error("Ollama service not available or no models loaded");
    }
    const model = service.models.includes(this.settings.model) ? this.settings.model : service.models[0];
    const endpoint = `${this.settings.ollamaUrl}/api/chat`;
    try {
      const resp = await fetch(endpoint, {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model,
          messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: userPrompt }
          ],
          stream: false,
          options: {
            temperature: this.settings.temperature,
            num_predict: this.settings.maxTokens
          }
        }),
        signal: this.createTimeoutSignal(this.settings.timeout * 1e3)
      });
      if (!resp.ok) {
        const text = await resp.text();
        console.error("Ollama error", resp.status, text);
        throw new Error(`Ollama API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      return ((_a = json == null ? void 0 : json.message) == null ? void 0 : _a.content) || null;
    } catch (e) {
      console.error("callOllama error", e);
      throw e;
    }
  }
  async callLMStudio(systemPrompt, userPrompt) {
    var _a, _b, _c;
    const service = this.serviceCache.get("lmstudio");
    if (!(service == null ? void 0 : service.available) || !service.models.length) {
      throw new Error("LM Studio service not available or no models loaded");
    }
    const model = service.models.includes(this.settings.model) ? this.settings.model : service.models[0];
    const endpoint = `${this.settings.lmstudioUrl}/v1/chat/completions`;
    try {
      const resp = await fetch(endpoint, {
        method: "POST",
        headers: {
          "Authorization": "Bearer lm-studio",
          // Placeholder auth
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model,
          messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: userPrompt }
          ],
          temperature: this.settings.temperature,
          max_tokens: this.settings.maxTokens
        }),
        signal: this.createTimeoutSignal(this.settings.timeout * 1e3)
      });
      if (!resp.ok) {
        const text = await resp.text();
        console.error("LM Studio error", resp.status, text);
        throw new Error(`LM Studio API error: ${resp.status} ${resp.statusText}`);
      }
      const json = await resp.json();
      return ((_c = (_b = (_a = json == null ? void 0 : json.choices) == null ? void 0 : _a[0]) == null ? void 0 : _b.message) == null ? void 0 : _c.content) || null;
    } catch (e) {
      console.error("callLMStudio error", e);
      throw e;
    }
  }
};
var ExtractorSettingTab = class extends import_obsidian.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Task Extractor Settings" });
    this.addProviderSection(containerEl);
    this.addLocalLLMSection(containerEl);
    this.addProcessingSection(containerEl);
    this.addFrontmatterSection(containerEl);
    this.addAdvancedSection(containerEl);
  }
  addProviderSection(containerEl) {
    containerEl.createEl("h3", { text: "LLM Provider Configuration" });
    const statusEl = containerEl.createEl("div", { cls: "task-extractor-status" });
    this.updateServiceStatus(statusEl);
    new import_obsidian.Setting(containerEl).setName("Provider").setDesc("Choose LLM provider. Local providers (Ollama/LM Studio) require the service to be running.").addDropdown((cb) => cb.addOption("openai", "OpenAI").addOption("anthropic", "Anthropic").addOption("ollama", "Ollama (Local)").addOption("lmstudio", "LM Studio (Local)").setValue(this.plugin.settings.provider).onChange(async (v) => {
      this.plugin.settings.provider = v;
      await this.plugin.saveSettings();
      this.updateServiceStatus(statusEl);
      this.display();
    }));
    if (["openai", "anthropic"].includes(this.plugin.settings.provider)) {
      new import_obsidian.Setting(containerEl).setName("API Key").setDesc("Your API key for the selected provider.").addText((text) => text.setPlaceholder("sk-...").setValue(this.plugin.settings.apiKey).onChange(async (v) => {
        this.plugin.settings.apiKey = v.trim();
        await this.plugin.saveSettings();
      }));
    }
    this.addModelSetting(containerEl);
  }
  addModelSetting(containerEl) {
    const provider = this.plugin.settings.provider;
    const service = this.plugin.serviceCache.get(provider);
    if (["ollama", "lmstudio"].includes(provider) && (service == null ? void 0 : service.available) && service.models.length > 0) {
      new import_obsidian.Setting(containerEl).setName("Model").setDesc(`Select from ${service.models.length} available ${provider} models.`).addDropdown((cb) => {
        service.models.forEach((model) => cb.addOption(model, model));
        cb.setValue(this.plugin.settings.model || service.models[0]).onChange(async (v) => {
          this.plugin.settings.model = v;
          await this.plugin.saveSettings();
        });
      });
    } else {
      const defaultModels = {
        openai: "gpt-4o-mini",
        anthropic: "claude-3-sonnet-20240229",
        ollama: "llama3.2",
        lmstudio: "local-model"
      };
      new import_obsidian.Setting(containerEl).setName("Model").setDesc(`Model name for ${provider}. ${["ollama", "lmstudio"].includes(provider) ? "Make sure the model is loaded in " + provider + "." : ""}`).addText((text) => text.setPlaceholder(defaultModels[provider]).setValue(this.plugin.settings.model).onChange(async (v) => {
        this.plugin.settings.model = v.trim();
        await this.plugin.saveSettings();
      }));
    }
  }
  addLocalLLMSection(containerEl) {
    if (!["ollama", "lmstudio"].includes(this.plugin.settings.provider))
      return;
    containerEl.createEl("h3", { text: "Local LLM Configuration" });
    if (this.plugin.settings.provider === "ollama") {
      new import_obsidian.Setting(containerEl).setName("Ollama URL").setDesc("URL for your Ollama instance.").addText((text) => text.setValue(this.plugin.settings.ollamaUrl).onChange(async (v) => {
        this.plugin.settings.ollamaUrl = v.trim();
        await this.plugin.saveSettings();
        await this.plugin.detectServices();
      }));
    }
    if (this.plugin.settings.provider === "lmstudio") {
      new import_obsidian.Setting(containerEl).setName("LM Studio URL").setDesc("URL for your LM Studio instance.").addText((text) => text.setValue(this.plugin.settings.lmstudioUrl).onChange(async (v) => {
        this.plugin.settings.lmstudioUrl = v.trim();
        await this.plugin.saveSettings();
        await this.plugin.detectServices();
      }));
    }
    new import_obsidian.Setting(containerEl).setName("Model Refresh Interval").setDesc("How often to check for available models (minutes).").addSlider((slider) => slider.setLimits(1, 60, 1).setValue(this.plugin.settings.localModelRefreshInterval).setDynamicTooltip().onChange(async (v) => {
      this.plugin.settings.localModelRefreshInterval = v;
      await this.plugin.saveSettings();
      this.plugin.setupServiceMonitoring();
    }));
  }
  addProcessingSection(containerEl) {
    containerEl.createEl("h3", { text: "Processing Settings" });
    new import_obsidian.Setting(containerEl).setName("Owner name").setDesc("Exact name the LLM should look for when deciding tasks.").addText((text) => text.setPlaceholder("Bryan Kolb").setValue(this.plugin.settings.ownerName).onChange(async (v) => {
      this.plugin.settings.ownerName = v.trim();
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Tasks folder").setDesc("Folder where generated task notes will be created.").addText((text) => text.setValue(this.plugin.settings.tasksFolder).onChange(async (v) => {
      this.plugin.settings.tasksFolder = v.trim();
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Trigger note types").setDesc("Comma-separated list of note types to process (from frontmatter Type field).").addText((text) => text.setValue(this.plugin.settings.triggerTypes.join(", ")).onChange(async (v) => {
      this.plugin.settings.triggerTypes = v.split(",").map((s) => s.trim()).filter((s) => s.length > 0);
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Process edits as well as new files").setDesc("If enabled, modifications to matching notes will be processed too.").addToggle((toggle) => toggle.setValue(this.plugin.settings.processOnUpdate).onChange(async (v) => {
      this.plugin.settings.processOnUpdate = v;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Link back to source").setDesc("Insert a link back to the source note in generated task notes.").addToggle((toggle) => toggle.setValue(this.plugin.settings.linkBack).onChange(async (v) => {
      this.plugin.settings.linkBack = v;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Processed marker key").setDesc("Frontmatter key to mark processed notes.").addText((text) => text.setValue(this.plugin.settings.processedFrontmatterKey).onChange(async (v) => {
      this.plugin.settings.processedFrontmatterKey = v.trim();
      await this.plugin.saveSettings();
    }));
  }
  addFrontmatterSection(containerEl) {
    containerEl.createEl("h3", { text: "Task Note Frontmatter" });
    containerEl.createEl("p", { text: "Customize the frontmatter fields for generated task notes:" });
    new import_obsidian.Setting(containerEl).setName("Add Field").setDesc("Add a new frontmatter field").addButton((btn) => btn.setButtonText("Add Field").onClick(() => {
      this.plugin.settings.frontmatterFields.push({
        key: "new_field",
        defaultValue: "",
        type: "text",
        required: false
      });
      this.plugin.saveSettings();
      this.display();
    }));
    this.plugin.settings.frontmatterFields.forEach((field, index) => {
      const fieldContainer = containerEl.createDiv({ cls: "task-extractor-field" });
      new import_obsidian.Setting(fieldContainer).setName(`Field ${index + 1}: ${field.key}`).setDesc(`Type: ${field.type}, Required: ${field.required ? "Yes" : "No"}`).addButton((btn) => btn.setButtonText("Edit").onClick(() => this.editField(index))).addButton((btn) => btn.setButtonText("Remove").onClick(() => {
        this.plugin.settings.frontmatterFields.splice(index, 1);
        this.plugin.saveSettings();
        this.display();
      }));
    });
    new import_obsidian.Setting(containerEl).setName("Custom Prompt").setDesc("Override the default task extraction prompt. Leave empty to use default.").addTextArea((text) => text.setPlaceholder("Enter custom prompt...").setValue(this.plugin.settings.customPrompt).onChange(async (v) => {
      this.plugin.settings.customPrompt = v;
      await this.plugin.saveSettings();
    }));
  }
  addAdvancedSection(containerEl) {
    containerEl.createEl("h3", { text: "Advanced Settings" });
    new import_obsidian.Setting(containerEl).setName("Max Tokens").setDesc("Maximum tokens to generate.").addSlider((slider) => slider.setLimits(100, 2e3, 50).setValue(this.plugin.settings.maxTokens).setDynamicTooltip().onChange(async (v) => {
      this.plugin.settings.maxTokens = v;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Temperature").setDesc("Creativity level (0 = deterministic, 1 = creative).").addSlider((slider) => slider.setLimits(0, 1, 0.1).setValue(this.plugin.settings.temperature).setDynamicTooltip().onChange(async (v) => {
      this.plugin.settings.temperature = v;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Timeout (seconds)").setDesc("Request timeout for LLM calls.").addSlider((slider) => slider.setLimits(10, 120, 5).setValue(this.plugin.settings.timeout).setDynamicTooltip().onChange(async (v) => {
      this.plugin.settings.timeout = v;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Retry Attempts").setDesc("Number of retry attempts for failed requests.").addSlider((slider) => slider.setLimits(1, 5, 1).setValue(this.plugin.settings.retries).setDynamicTooltip().onChange(async (v) => {
      this.plugin.settings.retries = v;
      await this.plugin.saveSettings();
    }));
  }
  updateServiceStatus(statusEl) {
    var _a;
    statusEl.empty();
    const provider = this.plugin.settings.provider;
    const service = this.plugin.serviceCache.get(provider);
    if (["ollama", "lmstudio"].includes(provider)) {
      const status = (service == null ? void 0 : service.available) ? "\u{1F7E2} Available" : "\u{1F534} Not Available";
      const models = ((_a = service == null ? void 0 : service.models) == null ? void 0 : _a.length) || 0;
      statusEl.createEl("div", {
        text: `${provider.toUpperCase()} Status: ${status} (${models} models)`,
        cls: (service == null ? void 0 : service.available) ? "task-extractor-status-ok" : "task-extractor-status-error"
      });
    } else {
      statusEl.createEl("div", {
        text: `${provider.toUpperCase()}: Cloud service`,
        cls: "task-extractor-status-cloud"
      });
    }
  }
  editField(index) {
    const field = this.plugin.settings.frontmatterFields[index];
    const newKey = prompt("Enter field key:", field.key);
    if (newKey) {
      field.key = newKey;
      this.plugin.saveSettings();
      this.display();
    }
  }
};
